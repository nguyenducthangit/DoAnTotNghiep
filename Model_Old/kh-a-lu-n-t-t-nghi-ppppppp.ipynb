{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":6126678,"sourceType":"datasetVersion","datasetId":3512311}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# **Import the Libraries**"],"metadata":{"id":"Kv6Q3a7Lry_y"}},{"cell_type":"code","source":["!ps -aux|grep python"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T08:31:28.217068Z","iopub.execute_input":"2025-03-05T08:31:28.217417Z","iopub.status.idle":"2025-03-05T08:31:29.324304Z","shell.execute_reply.started":"2025-03-05T08:31:28.217379Z","shell.execute_reply":"2025-03-05T08:31:29.323044Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"UO5GZtK4ry_0","executionInfo":{"status":"ok","timestamp":1748544377281,"user_tz":-420,"elapsed":49,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}},"outputId":"db1806ea-b76e-41d7-f9a9-d66571c1a07d"},"outputs":[{"output_type":"stream","name":"stdout","text":["root          66  0.1  0.0      0     0 ?        Z    16:22   0:15 [python3] <defunct>\n","root          67  0.0  0.4  77384 57704 ?        S    16:22   0:00 python3 /usr/local/bin/colab-fileshim.py\n","root         116  0.0  1.0 386544 136052 ?       Sl   16:22   0:08 /usr/bin/python3 /usr/local/bin/jupyter-notebook --debug --transport=\"ipc\" --ip=172.28.0.12 --NotebookApp.token= --port=9000 --FileContentsManager.root_dir=/ --MappingKernelManager.root_dir=/content\n","root        4617  0.0  0.0   4364  3120 ?        S    16:40   0:00 bash -c tail -n +0 -F \"/root/.config/Google/DriveFS/Logs/drive_fs.txt\" | python3 /opt/google/drive/drive-filter.py > \"/root/.config/Google/DriveFS/Logs/timeouts.txt\" \n","root        4620  0.0  0.0  20884 12856 ?        S    16:40   0:00 python3 /opt/google/drive/drive-filter.py\n","root       23446  0.0  0.1 1241404 17860 ?       Sl   17:53   0:00 /usr/colab/bin/language_service --lsp_search_dirs=/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages --language_services_request_root_url=http://172.28.0.1:8013/ --language_services_request_timeout=30s -- node /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:e104ff60c0f068d202f49cb5728a64125b2f8643ba\n","root       36789 16.5  0.7 1181460 104916 ?      Ssl  18:46   0:01 /usr/bin/python3 -m colab_kernel_launcher -f /root/.local/share/jupyter/runtime/kernel-56ed57ca-7ecc-4774-a2f1-05676f9d2032.json\n","root       36819  5.0  0.1 544432 20128 ?        Sl   18:46   0:00 /usr/bin/python3 /usr/local/lib/python3.11/dist-packages/debugpy/adapter --for-server 42855 --host 127.0.0.1 --port 33743 --server-access-token a343b674172ff83244e11d83a3e34b8de9911f02932d824a963910e2ddfcbeb2\n","root       36854  0.5  0.1 1241404 18680 ?       Sl   18:46   0:00 /usr/colab/bin/language_service --lsp_search_dirs=/datalab/web/pyright/typeshed-fallback/stdlib,/usr/local/lib/python3.10/dist-packages --language_services_request_root_url=http://172.28.0.1:8013/ --language_services_request_timeout=30s -- node /datalab/web/pyright/pyright-langserver.js --stdio --cancellationReceive=file:eb5256cf09a4b425e158ba50d64020380cfb9f8a8f\n","root       36899  0.0  0.0   7376  3448 ?        S    18:46   0:00 /bin/bash -c ps -aux|grep python\n","root       36901  0.0  0.0   6484  2284 ?        S    18:46   0:00 grep python\n"]}],"execution_count":1},{"cell_type":"code","source":["import os\n","os.system(\"kill -9 1\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T09:30:22.949589Z","iopub.execute_input":"2025-03-04T09:30:22.950560Z","iopub.status.idle":"2025-03-04T09:30:22.959212Z","shell.execute_reply.started":"2025-03-04T09:30:22.950505Z","shell.execute_reply":"2025-03-04T09:30:22.958316Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"FcTo1A6nry_2","executionInfo":{"status":"ok","timestamp":1748544377282,"user_tz":-420,"elapsed":23,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}},"outputId":"515769ab-72b1-47f4-b0d3-209c1c9b1b5a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{},"execution_count":2}],"execution_count":2},{"cell_type":"code","source":["import pandas as pd\n","import tensorflow as tf\n","from sklearn import preprocessing\n","from sklearn.cluster import DBSCAN\n","from tabulate import tabulate\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","import seaborn as sns\n","import numpy as np\n","# importing required libraries for normalizing data\n","from sklearn.preprocessing import StandardScaler,LabelBinarizer,MinMaxScaler\n","from sklearn.neighbors import NearestNeighbors\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","# representation of model layers\n","from tensorflow.keras.utils import plot_model\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score , classification_report\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n","import joblib\n","from sklearn.svm import SVC\n","from sklearn.mixture import GaussianMixture\n","from sklearn.naive_bayes import GaussianNB"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T15:11:26.937426Z","iopub.execute_input":"2025-03-13T15:11:26.937760Z","iopub.status.idle":"2025-03-13T15:11:39.166304Z","shell.execute_reply.started":"2025-03-13T15:11:26.937729Z","shell.execute_reply":"2025-03-13T15:11:39.165596Z"},"id":"pshiIVb9ry_2","executionInfo":{"status":"ok","timestamp":1748544388203,"user_tz":-420,"elapsed":10929,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":["# **Visualisation**"],"metadata":{"id":"g6f2xcgMry_3"}},{"cell_type":"code","source":["print(\"GPU Available:\", tf.config.list_physical_devices('GPU'))\n","if not tf.config.list_physical_devices('GPU'):\n","    print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y GPU! H√£y ki·ªÉm tra c√†i ƒë·∫∑t Kaggle Notebook.\")\n","else:\n","    print(\"‚úÖ GPU ƒë√£ s·∫µn s√†ng ƒë·ªÉ s·ª≠ d·ª•ng!\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T10:37:05.596586Z","iopub.execute_input":"2025-03-13T10:37:05.597350Z","iopub.status.idle":"2025-03-13T10:37:06.447019Z","shell.execute_reply.started":"2025-03-13T10:37:05.597298Z","shell.execute_reply":"2025-03-13T10:37:06.446056Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"PuWJU-d0ry_3","executionInfo":{"status":"ok","timestamp":1748544388637,"user_tz":-420,"elapsed":430,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}},"outputId":"6827a93c-a7ff-4709-b9cc-bff902425672"},"outputs":[{"output_type":"stream","name":"stdout","text":["GPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","‚úÖ GPU ƒë√£ s·∫µn s√†ng ƒë·ªÉ s·ª≠ d·ª•ng!\n"]}],"execution_count":4},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hjxLq7WisPe5","executionInfo":{"status":"ok","timestamp":1748546162345,"user_tz":-420,"elapsed":1641,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}},"outputId":"981d2d3f-9cf9-4495-9a3a-e0178c0c84f3"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["import os\n","\n","path = \"/content/drive/MyDrive/Do_An_Tot_Nghiep/dataset/CICIoT2023/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\n","print(os.path.exists(path))"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T04:15:28.789914Z","iopub.execute_input":"2025-03-09T04:15:28.790295Z","iopub.status.idle":"2025-03-09T04:15:28.799229Z","shell.execute_reply.started":"2025-03-09T04:15:28.790263Z","shell.execute_reply":"2025-03-09T04:15:28.798237Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"7kaLnrQ8ry_4","executionInfo":{"status":"ok","timestamp":1748546163926,"user_tz":-420,"elapsed":1598,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}},"outputId":"06e4eae3-363b-4da2-92b2-f669125c20c7"},"outputs":[{"output_type":"stream","name":"stdout","text":["True\n"]}],"execution_count":3},{"cell_type":"code","source":["pip install rapidfuzz\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T10:37:12.428835Z","iopub.execute_input":"2025-03-13T10:37:12.429185Z","iopub.status.idle":"2025-03-13T10:37:20.812051Z","shell.execute_reply.started":"2025-03-13T10:37:12.429153Z","shell.execute_reply":"2025-03-13T10:37:20.810832Z"},"colab":{"base_uri":"https://localhost:8080/"},"id":"ffdMFm3Gry_4","executionInfo":{"status":"ok","timestamp":1748546174693,"user_tz":-420,"elapsed":10766,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}},"outputId":"ec45d550-040e-4bc1-b096-bd913031302e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rapidfuzz\n","  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: rapidfuzz\n","Successfully installed rapidfuzz-3.13.0\n"]}],"execution_count":4},{"cell_type":"code","source":["import os\n","import cudf  # S·ª≠ d·ª•ng cuDF ƒë·ªÉ tƒÉng t·ªëc x·ª≠ l√Ω d·ªØ li·ªáu b·∫±ng GPU\n","import matplotlib.pyplot as plt\n","\n","# üìÇ Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu\n","data_dir = \"/content/drive/MyDrive/Do_An_Tot_Nghiep/dataset/CICIoT2023/\"\n","\n","# üõ† ƒê·ªçc c√°c file CSV v√†o danh s√°ch\n","dfs = []\n","for i in range(0, 10):\n","    filename = f\"{data_dir}part-{str(i).zfill(5)}-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\n","\n","    if os.path.exists(filename):\n","        print(f\"üìÇ ƒê·ªçc file: {filename}\")\n","        df = cudf.read_csv(filename)\n","        dfs.append(df)\n","    else:\n","        print(f\"‚ö† File kh√¥ng t·ªìn t·∫°i: {filename}\")\n","\n","# üß™ Load file test (part-00168)\n","test_filename = f\"{data_dir}part-00168-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\n","if os.path.exists(test_filename):\n","    print(f\"üìÇ ƒê·ªçc file test: {test_filename}\")\n","    df_test = cudf.read_csv(test_filename)\n","else:\n","    print(f\"‚ö† File test kh√¥ng t·ªìn t·∫°i: {test_filename}\")\n","\n","# ‚úÖ N·ªëi d·ªØ li·ªáu n·∫øu c√≥\n","if dfs:\n","    df_full = cudf.concat(dfs, ignore_index=True)\n","    print(\"‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·ªëi th√†nh c√¥ng!\")\n","else:\n","    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë·ªÉ n·ªëi!\")\n","    df_full = None\n","\n","# üìä Ki·ªÉm tra nh√£n g·ªëc tr∆∞·ªõc khi g·ªôp\n","if df_full is not None and \"label\" in df_full.columns:\n","    # Chuy·ªÉn cuDF sang Pandas ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì\n","    df_pandas = df_full.to_pandas()\n","\n","    print(\"üìã Danh s√°ch nh√£n g·ªëc trong d·ªØ li·ªáu:\")\n","    print(df_pandas[\"label\"].value_counts())\n","\n","    # üìä V·∫Ω bi·ªÉu ƒë·ªì ph√¢n ph·ªëi nh√£n g·ªëc\n","    fig, ax = plt.subplots(figsize=(15, 9))\n","    label_counts = df_pandas[\"label\"].value_counts()\n","\n","    bars = ax.bar(label_counts.index, label_counts.values, width=0.8)\n","\n","    plt.xticks(rotation=45, ha='right')\n","    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n","    ax.set_xlabel('Labels')\n","    ax.set_ylabel('Count')\n","    ax.set_title('Original Label Distribution')\n","\n","    for bar in bars:\n","        height = bar.get_height()\n","        ax.annotate(f'{int(height):,}',\n","                    xy=(bar.get_x() + bar.get_width() / 2, height),\n","                    xytext=(0, 3),\n","                    textcoords=\"offset points\",\n","                    ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"‚ö† Kh√¥ng th·ªÉ ki·ªÉm tra nh√£n v√¨ d·ªØ li·ªáu r·ªóng ho·∫∑c thi·∫øu c·ªôt 'label'!\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T15:11:51.468063Z","iopub.execute_input":"2025-03-13T15:11:51.468986Z","iopub.status.idle":"2025-03-13T15:12:08.080814Z","shell.execute_reply.started":"2025-03-13T15:11:51.468951Z","shell.execute_reply":"2025-03-13T15:12:08.079926Z"},"colab":{"base_uri":"https://localhost:8080/","height":567},"id":"hubvBSLsry_5","executionInfo":{"status":"error","timestamp":1748546657582,"user_tz":-420,"elapsed":44,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}},"outputId":"6e2ffbce-9af9-43aa-aff3-cd7f1e9e6aa2"},"outputs":[{"output_type":"stream","name":"stdout","text":["üìÇ ƒê·ªçc file: /content/drive/MyDrive/Do_An_Tot_Nghiep/dataset/CICIoT2023/part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\n"]},{"output_type":"error","ename":"MemoryError","evalue":"std::bad_alloc: CUDA error at: /pyenv/versions/3.12.9/lib/python3.12/site-packages/librmm/include/rmm/mr/device/cuda_memory_resource.hpp:62: cudaErrorInsufficientDriver CUDA driver version is insufficient for CUDA runtime version","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-7aa3a58bff52>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"üìÇ ƒê·ªçc file: {filename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mdfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/utils/performance_tracking.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m                     )\n\u001b[1;32m     50\u001b[0m                 )\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/cudf/io/csv.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, prefix, mangle_dupe_cols, dtype, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, dayfirst, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, comment, delim_whitespace, byte_range, storage_options, bytes_per_thread)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_na_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mna_values\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m     \u001b[0mtable_w_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m     data = {\n\u001b[1;32m    259\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mColumn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pylibcudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mcsv.pyx\u001b[0m in \u001b[0;36mpylibcudf.io.csv.read_csv\u001b[0;34m()\u001b[0m\n","\u001b[0;32mcsv.pyx\u001b[0m in \u001b[0;36mpylibcudf.io.csv.read_csv\u001b[0;34m()\u001b[0m\n","\u001b[0;31mMemoryError\u001b[0m: std::bad_alloc: CUDA error at: /pyenv/versions/3.12.9/lib/python3.12/site-packages/librmm/include/rmm/mr/device/cuda_memory_resource.hpp:62: cudaErrorInsufficientDriver CUDA driver version is insufficient for CUDA runtime version"]}],"execution_count":6},{"cell_type":"code","source":["import os\n","import cudf  # S·ª≠ d·ª•ng cuDF ƒë·ªÉ tƒÉng t·ªëc x·ª≠ l√Ω d·ªØ li·ªáu b·∫±ng GPU\n","import matplotlib.pyplot as plt\n","\n","# üìÇ Th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu\n","data_dir = \"/content/drive/MyDrive/Do_An_Tot_Nghiep/dataset/CICIoT2023/\"\n","\n","# üõ† ƒê·ªçc c√°c file CSV v√†o danh s√°ch\n","dfs = []\n","for i in range(0, 10):\n","    filename = f\"{data_dir}part-{str(i).zfill(5)}-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\n","\n","    if os.path.exists(filename):\n","        print(f\"üìÇ ƒê·ªçc file: {filename}\")\n","        df = cudf.read_csv(filename)\n","        dfs.append(df)\n","    else:\n","        print(f\"‚ö† File kh√¥ng t·ªìn t·∫°i: {filename}\")\n","\n","# üß™ Load file test (part-00168)\n","test_filename = f\"{data_dir}part-00168-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\n","if os.path.exists(test_filename):\n","    print(f\"üìÇ ƒê·ªçc file test: {test_filename}\")\n","    df_test = cudf.read_csv(test_filename)\n","else:\n","    print(f\"‚ö† File test kh√¥ng t·ªìn t·∫°i: {test_filename}\")\n","\n","# ‚úÖ N·ªëi d·ªØ li·ªáu n·∫øu c√≥\n","if dfs:\n","    df_full = cudf.concat(dfs, ignore_index=True)\n","    print(\"‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·ªëi th√†nh c√¥ng!\")\n","else:\n","    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë·ªÉ n·ªëi!\")\n","    df_full = None\n","\n","# üìä V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë nh√£n n·∫øu d·ªØ li·ªáu h·ª£p l·ªá\n","if df_full is not None and \"label\" in df_full.columns:\n","    # Chuy·ªÉn cuDF sang Pandas ƒë·ªÉ v·∫Ω bi·ªÉu ƒë·ªì\n","    df_filtered_pandas = df_full.to_pandas()\n","\n","    fig, ax = plt.subplots(figsize=(15, 9))\n","    label_counts = df_filtered_pandas[\"label\"].value_counts()\n","\n","    bars = ax.bar(label_counts.index, label_counts.values, width=0.8)\n","\n","    # üé® ƒê·ªãnh d·∫°ng bi·ªÉu ƒë·ªì\n","    plt.xticks(rotation=45, ha='right')\n","    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n","    ax.set_xlabel('Labels')\n","    ax.set_ylabel('Count')\n","    ax.set_title('Distribution of Labels')\n","\n","    # üè∑ Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng tr√™n c·ªôt\n","    for bar in bars:\n","        height = bar.get_height()\n","        ax.annotate(f'{int(height):,}',\n","                    xy=(bar.get_x() + bar.get_width() / 2, height),\n","                    xytext=(0, 3),\n","                    textcoords=\"offset points\",\n","                    ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    plt.show()\n","else:\n","    print(\"‚ö† Kh√¥ng th·ªÉ v·∫Ω bi·ªÉu ƒë·ªì v√¨ df_full r·ªóng ho·∫∑c thi·∫øu c·ªôt 'label'!\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T15:12:16.445398Z","iopub.execute_input":"2025-03-13T15:12:16.446031Z","iopub.status.idle":"2025-03-13T15:12:19.209786Z","shell.execute_reply.started":"2025-03-13T15:12:16.445996Z","shell.execute_reply":"2025-03-13T15:12:19.208911Z"},"id":"jrB2G8ZIry_5","executionInfo":{"status":"aborted","timestamp":1748546187301,"user_tz":-420,"elapsed":1,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["df.info()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T11:05:19.460604Z","iopub.execute_input":"2025-03-13T11:05:19.460973Z","iopub.status.idle":"2025-03-13T11:05:19.486204Z","shell.execute_reply.started":"2025-03-13T11:05:19.460940Z","shell.execute_reply":"2025-03-13T11:05:19.485300Z"},"id":"8eS5SpCDry_6","executionInfo":{"status":"aborted","timestamp":1748546187303,"user_tz":-420,"elapsed":26867,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Danh s√°ch giao th·ª©c\n","protocols = ['HTTP', 'HTTPS', 'DNS', 'Telnet', 'SMTP', 'SSH', 'IRC', 'TCP', 'UDP', 'DHCP', 'ARP', 'ICMP', 'IPv', 'LLC']\n","\n","# T√≠nh t·ªïng s·ªë l·∫ßn xu·∫•t hi·ªán c·ªßa m·ªói giao th·ª©c\n","protocol_counts = df[protocols].sum().sort_values(ascending=False)\n","\n","# Chuy·ªÉn t·ª´ cuDF Series ‚Üí Pandas Series\n","protocol_counts_pandas = protocol_counts.to_pandas()\n","\n","# V·∫Ω bi·ªÉu ƒë·ªì\n","plt.figure(figsize=(14, 8))\n","protocol_counts_pandas.plot(kind='bar')\n","plt.title('Protocol Usage Counts')\n","plt.xlabel('Protocol')\n","plt.ylabel('Count')\n","plt.xticks(rotation=45, ha='right')  # Xoay nh√£n tr·ª•c X\n","plt.tight_layout()  # CƒÉn ch·ªânh b·ªë c·ª•c\n","plt.show()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T14:23:27.854500Z","iopub.execute_input":"2025-03-13T14:23:27.855192Z","iopub.status.idle":"2025-03-13T14:23:28.291013Z","shell.execute_reply.started":"2025-03-13T14:23:27.855158Z","shell.execute_reply":"2025-03-13T14:23:28.290042Z"},"id":"FDLlKqnIry_7","executionInfo":{"status":"aborted","timestamp":1748546187305,"user_tz":-420,"elapsed":26866,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# T√≠nh to√°n c√°c ch·ªâ s·ªë\n","average_flow_duration = df['flow_duration'].mean()\n","max_protocol_usage = df[protocols].sum().max()\n","\n","# Chuy·ªÉn cuDF Series sang Pandas tr∆∞·ªõc khi g·ªçi idxmax()\n","top_attack_type = df['label'].value_counts().to_pandas().idxmax()\n","\n","# T·∫°o figure\n","fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n","fig.suptitle('Network Traffic Scorecard', fontsize=20)\n","\n","# Scorecard cho th·ªùi gian trung b√¨nh c·ªßa lu·ªìng d·ªØ li·ªáu\n","axs[0].text(0.5, 0.5, f'Avg Flow Duration\\n{average_flow_duration:.2f} sec',\n","            fontsize=15, ha='center', va='center')\n","axs[0].set_axis_off()\n","\n","# Scorecard cho giao th·ª©c ph·ªï bi·∫øn nh·∫•t\n","axs[1].text(0.5, 0.5, f'Max Protocol Usage\\n{max_protocol_usage}',\n","            fontsize=15, ha='center', va='center')\n","axs[1].set_axis_off()\n","\n","# Scorecard cho ki·ªÉu t·∫•n c√¥ng ph·ªï bi·∫øn nh·∫•t\n","axs[2].text(0.5, 0.5, f'Top Attack Type\\n{top_attack_type}',\n","            fontsize=15, ha='center', va='center')\n","axs[2].set_axis_off()\n","\n","# Hi·ªÉn th·ªã bi·ªÉu ƒë·ªì\n","plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n","plt.show()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T14:23:38.574244Z","iopub.execute_input":"2025-03-13T14:23:38.575218Z","iopub.status.idle":"2025-03-13T14:23:38.797218Z","shell.execute_reply.started":"2025-03-13T14:23:38.575174Z","shell.execute_reply":"2025-03-13T14:23:38.795368Z"},"id":"t9Riswypry_7","executionInfo":{"status":"aborted","timestamp":1748546187306,"user_tz":-420,"elapsed":26863,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import cudf  # D√πng cuDF ƒë·ªÉ x·ª≠ l√Ω d·ªØ li·ªáu nhanh h∆°n tr√™n GPU\n","\n","# üü¢ H√†m thay ƒë·ªïi nh√£n v·ªÅ 8 nh√≥m ch√≠nh (ƒê√£ c·∫≠p nh·∫≠t ƒë·∫ßy ƒë·ªß nh√£n)\n","def change_label(df):\n","    mapping = {\n","        'DDoS-ICMP_Flood': 'DDos', 'DDoS-UDP_Flood': 'DDos', 'DDoS-TCP_Flood': 'DDos',\n","        'DDoS-PSHACK_Flood': 'DDos', 'DDoS-SYN_Flood': 'DDos', 'DDoS-RSTFINFlood': 'DDos',\n","        'DDoS-SynonymousIP_Flood': 'DDos', 'DDoS-ICMP_Fragmentation': 'DDos',\n","        'DDoS-UDP_Fragmentation': 'DDos', 'DDoS-ACK_Fragmentation': 'DDos',\n","        'DDoS-HTTP_Flood': 'DDos', 'DDoS-SlowLoris': 'DDos',\n","\n","        'DoS-UDP_Flood': 'DoS', 'DoS-TCP_Flood': 'DoS', 'DoS-SYN_Flood': 'DoS', 'DoS-HTTP_Flood': 'DoS',\n","\n","        'Recon-HostDiscovery': 'Recon', 'Recon-OSScan': 'Recon', 'Recon-PortScan': 'Recon',\n","        'Recon-PingSweep': 'Recon', 'VulnerabilityScan': 'Recon',\n","\n","        'MITM-ArpSpoofing': 'Spoofing', 'DNS_Spoofing': 'Spoofing',\n","\n","        'DictionaryBruteForce': 'BruteForce',\n","\n","        'BrowserHijacking': 'Web-based', 'XSS': 'Web-based', 'Uploading_Attack': 'Web-based',\n","        'SqlInjection': 'Web-based', 'CommandInjection': 'Web-based', 'Backdoor_Malware': 'Web-based',\n","\n","        'Mirai-greeth_flood': 'Mirai', 'Mirai-udpplain': 'Mirai', 'Mirai-greip_flood': 'Mirai',\n","\n","        'BenignTraffic': 'BENIGN'\n","    }\n","\n","    df[\"label\"] = df[\"label\"].map(mapping).fillna(df[\"label\"])  # Ch·ªâ thay ƒë·ªïi nh√£n c√≥ trong mapping\n","\n","# üü¢ ƒê·ªçc d·ªØ li·ªáu t·ª´ th∆∞ m·ª•c Kaggle\n","data_dir = \"/content/drive/MyDrive/Do_An_Tot_Nghiep/dataset/CICIoT2023/\"\n","\n","# üõ† ƒê·ªçc c√°c file CSV v√†o danh s√°ch\n","dfs = []\n","for i in range(0, 10):\n","    filename = f\"{data_dir}part-{str(i).zfill(5)}-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\n","\n","    if os.path.exists(filename):\n","        print(f\"üìÇ ƒê·ªçc file: {filename}\")\n","        df = cudf.read_csv(filename)\n","        dfs.append(df)\n","    else:\n","        print(f\"‚ö† File kh√¥ng t·ªìn t·∫°i: {filename}\")\n","\n","# ‚úÖ N·ªëi d·ªØ li·ªáu n·∫øu c√≥\n","if dfs:\n","    df_full = cudf.concat(dfs, ignore_index=True)\n","    print(\"‚úÖ D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c n·ªëi th√†nh c√¥ng!\")\n","else:\n","    print(\"‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu n√†o ƒë·ªÉ n·ªëi!\")\n","    df_full = None\n","\n","# üü¢ √Åp d·ª•ng g·ªôp nh√£n n·∫øu d·ªØ li·ªáu h·ª£p l·ªá\n","if df_full is not None and \"label\" in df_full.columns:\n","    change_label(df_full)\n","\n","    # üü¢ Chuy·ªÉn v·ªÅ Pandas ƒë·ªÉ ki·ªÉm tra & v·∫Ω bi·ªÉu ƒë·ªì\n","    df_pandas = df_full.to_pandas()\n","\n","    # üü¢ Ki·ªÉm tra danh s√°ch nh√£n sau khi g·ªôp\n","    print(\"\\nüìã Danh s√°ch nh√£n sau khi g·ªôp:\")\n","    print(df_pandas[\"label\"].value_counts())\n","\n","    # üü¢ Ki·ªÉm tra xem c√≥ nh√£n n√†o ch∆∞a ƒë∆∞·ª£c g·ªôp\n","    valid_labels = {'DDos', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN'}\n","    unmapped_labels = set(df_pandas[\"label\"].unique()) - valid_labels\n","\n","    print(\"\\nüîç Nh√£n ch∆∞a ƒë∆∞·ª£c g·ªôp:\")\n","    print(unmapped_labels if unmapped_labels else \"‚úÖ Kh√¥ng c√≥ nh√£n n√†o b·ªã b·ªè s√≥t!\")\n","\n","    # üü¢ V·∫Ω bi·ªÉu ƒë·ªì ph√¢n b·ªë nh√£n sau khi g·ªôp\n","    fig, ax = plt.subplots(figsize=(10, 5))\n","    label_counts = df_pandas[\"label\"].value_counts()\n","\n","    bars = ax.bar(label_counts.index, label_counts.values, width=0.5)\n","    plt.xticks(rotation=45, ha='right')\n","    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n","    ax.set_xlabel('Labels')\n","    ax.set_ylabel('Count')\n","    ax.set_title('Distribution of Labels After Merging')\n","\n","    for bar in bars:\n","        height = bar.get_height()\n","        ax.annotate(f'{int(height):,}',\n","                    xy=(bar.get_x() + bar.get_width() / 2, height),\n","                    xytext=(0, 3),\n","                    textcoords=\"offset points\",\n","                    ha='center', va='bottom')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","else:\n","    print(\"‚ö† Kh√¥ng th·ªÉ th·ª±c hi·ªán g·ªôp nh√£n v√¨ d·ªØ li·ªáu r·ªóng ho·∫∑c thi·∫øu c·ªôt 'label'!\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T15:12:36.666025Z","iopub.execute_input":"2025-03-13T15:12:36.666618Z","iopub.status.idle":"2025-03-13T15:12:39.113367Z","shell.execute_reply.started":"2025-03-13T15:12:36.666585Z","shell.execute_reply":"2025-03-13T15:12:39.112490Z"},"id":"gwroks-Try_8","executionInfo":{"status":"aborted","timestamp":1748546187308,"user_tz":-420,"elapsed":26861,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["from imblearn.over_sampling import SMOTE\n","from imblearn.under_sampling import RandomUnderSampler\n","from imblearn.pipeline import Pipeline\n","import numpy as np\n","\n","# üü¢ Chuy·ªÉn cuDF sang Pandas n·∫øu c·∫ßn\n","if hasattr(df_full, \"to_pandas\"):\n","    df_balanced = df_full.to_pandas()\n","else:\n","    df_balanced = df_full.copy()\n","\n","# üü¢ L·∫•y nh√£n v√† d·ªØ li·ªáu\n","X = df_balanced.drop(columns=['label'])  # C√°c ƒë·∫∑c tr∆∞ng\n","y = df_balanced['label']  # Nh√£n\n","\n","# üìä Xem ph√¢n ph·ªëi tr∆∞·ªõc khi c√¢n b·∫±ng\n","print(\"\\nüìä Ph√¢n ph·ªëi nh√£n ban ƒë·∫ßu:\")\n","print(y.value_counts())\n","\n","# üü¢ X√°c ƒë·ªãnh s·ªë l∆∞·ª£ng m·∫´u m·ª•c ti√™u cho m·ªói l·ªõp\n","target_counts = y.value_counts()\n","\n","# üõ† **T·ªëi ∆∞u chi·∫øn l∆∞·ª£c c√¢n b·∫±ng**\n","max_threshold = int(target_counts.max() * 0.2)  # Gi·∫£m l·ªõp l·ªõn nh·∫•t xu·ªëng 20%\n","min_threshold = int(target_counts.min() * 15)  # TƒÉng l·ªõp nh·ªè nh·∫•t l√™n 15 l·∫ßn\n","\n","sampling_strategy_under = {cls: max_threshold for cls in target_counts.index if target_counts[cls] > max_threshold}\n","sampling_strategy_over = {cls: min_threshold for cls in target_counts.index if target_counts[cls] < min_threshold}\n","\n","# üèó Pipeline k·∫øt h·ª£p **Undersampling + SMOTE**\n","pipeline = Pipeline([\n","    ('undersample', RandomUnderSampler(sampling_strategy=sampling_strategy_under, random_state=42)),\n","    ('smote', SMOTE(sampling_strategy=sampling_strategy_over, random_state=42))\n","])\n","\n","# üöÄ C√¢n b·∫±ng d·ªØ li·ªáu\n","X_resampled, y_resampled = pipeline.fit_resample(X, y)\n","\n","# üü¢ T·∫°o DataFrame m·ªõi sau c√¢n b·∫±ng\n","df_resampled = pd.DataFrame(X_resampled, columns=X.columns)\n","df_resampled['label'] = y_resampled\n","\n","# üìä Ki·ªÉm tra l·∫°i ph√¢n ph·ªëi nh√£n sau khi c√¢n b·∫±ng\n","print(\"\\nüìä Ph√¢n ph·ªëi nh√£n sau c√¢n b·∫±ng:\")\n","print(df_resampled[\"label\"].value_counts())\n","\n","# üìä V·∫Ω bi·ªÉu ƒë·ªì ph√¢n ph·ªëi sau khi c√¢n b·∫±ng\n","fig, ax = plt.subplots(figsize=(10, 5))\n","label_counts = df_resampled[\"label\"].value_counts()\n","\n","bars = ax.bar(label_counts.index, label_counts.values, width=0.5)\n","plt.xticks(rotation=45, ha='right')\n","ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n","ax.set_xlabel('Labels')\n","ax.set_ylabel('Count')\n","ax.set_title('Distribution of Labels After Improved Balancing')\n","\n","for bar in bars:\n","    height = bar.get_height()\n","    ax.annotate(f'{int(height):,}',\n","                xy=(bar.get_x() + bar.get_width() / 2, height),\n","                xytext=(0, 3),\n","                textcoords=\"offset points\",\n","                ha='center', va='bottom')\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T15:12:50.516399Z","iopub.execute_input":"2025-03-13T15:12:50.517290Z","iopub.status.idle":"2025-03-13T15:13:03.924739Z","shell.execute_reply.started":"2025-03-13T15:12:50.517255Z","shell.execute_reply":"2025-03-13T15:13:03.923922Z"},"id":"vtWz4NLZry_8","executionInfo":{"status":"aborted","timestamp":1748546187311,"user_tz":-420,"elapsed":26860,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from imblearn.over_sampling import SMOTE\n","\n","# H√†m thay ƒë·ªïi nh√£n v·ªÅ 7 nh√≥m ch√≠nh\n","def change_label(df):\n","    df.label.replace([\n","\n","        'DDoS-SYN_Flood','DDoS-RSTFINFlood','DDoS-SynonymousIP_Flood','DDoS-ICMP_Fragmentation',\n","        'DDoS-UDP_Fragmentation','DDoS-ACK_Fragmentation','DDoS-HTTP_Flood','DDoS-SlowLoris'\n","    ], 'DDos', inplace=True)\n","\n","    df.label.replace(['DoS-UDP_Flood','DoS-TCP_Flood','DoS-SYN_Flood','DoS-HTTP_Flood'], 'DoS', inplace=True)\n","    df.label.replace(['Recon-HostDiscovery','Recon-OSScan','Recon-PortScan','Recon-PingSweep','VulnerabilityScan'], 'Recon', inplace=True)\n","    df.label.replace(['MITM-ArpSpoofing','DNS_Spoofing'], 'Spoofing', inplace=True)\n","    df.label.replace(['DictionaryBruteForce'], 'BruteForce', inplace=True)\n","    df.label.replace(['BrowserHijacking','XSS','Uploading_Attack','SqlInjection','CommandInjection','Backdoor_Malware'], 'Web-based', inplace=True)\n","    df.label.replace(['Mirai-greeth_flood','Mirai-udpplain','Mirai-greip_flood'], 'Mirai', inplace=True)\n","    df.label.replace(['BenignTraffic'], 'BENIGN', inplace=True)\n","\n","# Thay ƒë·ªïi nh√£n trong dataset\n","change_label(df)\n","change_label(df_test)\n","\n","# Ch·ªçn c√°c l·ªõp ƒë√£ ƒë∆∞·ª£c gom nh√≥m\n","selected_classes = ['DDos', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n","df_selected = df[df['label'].isin(selected_classes)]\n","df_selected_test = df_test[df_test['label'].isin(selected_classes)]\n","\n","# Chuy·ªÉn cuDF sang Pandas tr∆∞·ªõc khi x·ª≠ l√Ω\n","if hasattr(df_selected, \"to_pandas\"):\n","    df_selected = df_selected.to_pandas()\n","\n","# √Åp d·ª•ng SMOTE\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(df_selected.drop(columns=['label']).to_numpy(), df_selected['label'].to_numpy())\n","\n","# T·∫°o dataframe m·ªõi sau khi SMOTE\n","df_balanced = pd.DataFrame(X_resampled, columns=df_selected.drop(columns=['label']).columns)\n","df_balanced['label'] = y_resampled\n","\n","# V·∫Ω bi·ªÉu ƒë·ªì ph√¢n ph·ªëi sau khi SMOTE\n","x_label_distribute = np.array(df_balanced['label'].value_counts().index)\n","y_label_distribute = np.array(df_balanced['label'].value_counts().values)\n","\n","fig = plt.figure(figsize=(10, 5))\n","bars = plt.bar(x_label_distribute, y_label_distribute, width=0.5, align='center')\n","plt.bar_label(bars, label_type='edge', fontsize=10)\n","plt.xticks(rotation=45, ha='right')\n","plt.gca().yaxis.set_major_formatter(plt.FuncFormatter(lambda x, _: f'{int(x):,}'))\n","plt.xlabel('Labels')\n","plt.ylabel('Count')\n","plt.title('Distribution of Labels After SMOTE')\n","plt.tight_layout()\n","plt.show()\n","\n","# Ki·ªÉm tra l·∫°i ph√¢n ph·ªëi\n","print(df_balanced['label'].value_counts())\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T10:58:13.798746Z","iopub.execute_input":"2025-03-13T10:58:13.799098Z","iopub.status.idle":"2025-03-13T10:58:20.271842Z","shell.execute_reply.started":"2025-03-13T10:58:13.799067Z","shell.execute_reply":"2025-03-13T10:58:20.270856Z"},"id":"22B04lFzry_9","executionInfo":{"status":"aborted","timestamp":1748546187314,"user_tz":-420,"elapsed":26859,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(type(df))  # Ki·ªÉm tra df c√≥ ph·∫£i cuDF kh√¥ng\n","print(df[\"label\"].unique())  # Ki·ªÉm tra nh√£n c√≥ ƒë·ªß kh√¥ng\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T12:55:59.676945Z","iopub.execute_input":"2025-03-13T12:55:59.678486Z","iopub.status.idle":"2025-03-13T12:55:59.704290Z","shell.execute_reply.started":"2025-03-13T12:55:59.678434Z","shell.execute_reply":"2025-03-13T12:55:59.703104Z"},"id":"BsRnYcu3ry_9","executionInfo":{"status":"aborted","timestamp":1748546187370,"user_tz":-420,"elapsed":26911,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **Transformation and standardization**"],"metadata":{"id":"iOdq5ikKry_9"}},{"cell_type":"code","source":["# Chuy·ªÉn c·ªôt label t·ª´ cuDF sang pandas\n","label = pd.DataFrame(df[\"label\"].to_pandas())\n","\n","# Hi·ªÉn th·ªã d·ªØ li·ªáu\n","print(label.head())"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T14:05:43.738193Z","iopub.execute_input":"2025-03-13T14:05:43.739361Z","iopub.status.idle":"2025-03-13T14:05:43.760986Z","shell.execute_reply.started":"2025-03-13T14:05:43.739320Z","shell.execute_reply":"2025-03-13T14:05:43.759977Z"},"id":"T9c7qCmRry_9","executionInfo":{"status":"aborted","timestamp":1748546187372,"user_tz":-420,"elapsed":26909,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Scale data will convert scale data or data format to the same range to avoid too large data affecting the model\n","# Scale data for each numeric feature with the train dataset\n","# Scale using MinMaxScaler to avoid negative values\n","# Here we only need to scale numeric features and numeric attributes because only numeric attributes have a large range\n","def scaleStandardData(dataFrame, numeric_cols):\n","  scaler = preprocessing.StandardScaler()\n","  for col in numeric_cols:\n","    arr = dataFrame[col]\n","    arr = np.array(arr)\n","    dataFrame[col] = scaler.fit_transform(arr.reshape(len(arr),1))\n","  return dataFrame\n","\n","def scaleMinMaxData(dataFrame, numeric_cols):\n","  scaler = preprocessing.MinMaxScaler()\n","  for col in numeric_cols:\n","    arr = dataFrame[col]\n","    arr = np.array(arr)\n","    dataFrame[col] = scaler.fit_transform(arr.reshape(len(arr),1))\n","  return dataFrame\n","\n","def scaleData(dataFrame, numeric_cols):\n","  dataFrame = scaleStandardData(dataFrame, numeric_cols)\n","  dataFrame = scaleMinMaxData(dataFrame, numeric_cols)\n","  return dataFrame"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:13:00.676238Z","iopub.execute_input":"2025-03-13T13:13:00.676993Z","iopub.status.idle":"2025-03-13T13:13:00.683698Z","shell.execute_reply.started":"2025-03-13T13:13:00.676960Z","shell.execute_reply":"2025-03-13T13:13:00.682678Z"},"id":"fs6sK53Rry_9","executionInfo":{"status":"aborted","timestamp":1748546187447,"user_tz":-420,"elapsed":64,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["Y_TRAIN = df_selected['label']\n","Y_TEST = df_selected_test['label']\n","X_TRAIN = df_selected.drop('label', axis=1).copy()\n","X_TEST = df_selected_test.drop('label', axis=1).copy()\n","\n","import numpy as np\n","\n","# Ki·ªÉm tra v√† chuy·ªÉn ƒë·ªïi t·∫•t c·∫£ c√°c c·ªôt float64 th√†nh float64 (tr√°nh float128)\n","float_cols = X_TRAIN.select_dtypes(include=['float64']).columns\n","X_TRAIN[float_cols] = X_TRAIN[float_cols].astype(np.float64)\n","\n","float_cols = X_TEST.select_dtypes(include=['float64']).columns\n","X_TEST[float_cols] = X_TEST[float_cols].astype(np.float64)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:13:04.275024Z","iopub.execute_input":"2025-03-13T13:13:04.275388Z","iopub.status.idle":"2025-03-13T13:13:04.439904Z","shell.execute_reply.started":"2025-03-13T13:13:04.275355Z","shell.execute_reply":"2025-03-13T13:13:04.438884Z"},"id":"US4VZlu0ry_-","executionInfo":{"status":"aborted","timestamp":1748546187448,"user_tz":-420,"elapsed":13,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# T·∫°o t·ª´ ƒëi·ªÉn √°nh x·∫°\n","label_mapping = {\n","    'BENIGN': 0, 'DDos': 1, 'DoS': 2, 'Mirai': 3,\n","    'Spoofing': 4, 'Recon': 5, 'Web-based': 6, 'BruteForce': 7\n","}\n","\n","# S·ª≠ d·ª•ng map() ƒë·ªÉ thay th·∫ø nh√£n\n","Y_TRAIN = Y_TRAIN.map(label_mapping)\n","Y_TEST = Y_TEST.map(label_mapping)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:13:06.883078Z","iopub.execute_input":"2025-03-13T13:13:06.883433Z","iopub.status.idle":"2025-03-13T13:13:06.918558Z","shell.execute_reply.started":"2025-03-13T13:13:06.883401Z","shell.execute_reply":"2025-03-13T13:13:06.917697Z"},"id":"msxa8dSwry_-","executionInfo":{"status":"aborted","timestamp":1748546187449,"user_tz":-420,"elapsed":11,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(Y_TRAIN.unique())  # Ki·ªÉm tra xem c√≥ gi√° tr·ªã NaN kh√¥ng\n","print(Y_TRAIN.isnull().sum())  # N·∫øu c√≥ NaN, s·ª≠a l·ªói tr∆∞·ªõc khi train\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:13:10.291358Z","iopub.execute_input":"2025-03-13T13:13:10.291982Z","iopub.status.idle":"2025-03-13T13:13:10.300367Z","shell.execute_reply.started":"2025-03-13T13:13:10.291946Z","shell.execute_reply":"2025-03-13T13:13:10.299456Z"},"id":"GHNFzlltry_-","executionInfo":{"status":"aborted","timestamp":1748546187450,"user_tz":-420,"elapsed":10,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(X_TRAIN.describe())  # Ki·ªÉm tra xem d·ªØ li·ªáu c√≥ b·ªã bi·∫øn ƒë·ªïi b·∫•t th∆∞·ªùng kh√¥ng\n","print(X_TEST.describe())\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-05T09:47:32.352276Z","iopub.execute_input":"2025-03-05T09:47:32.352717Z","iopub.status.idle":"2025-03-05T09:47:34.691702Z","shell.execute_reply.started":"2025-03-05T09:47:32.352677Z","shell.execute_reply":"2025-03-05T09:47:34.690591Z"},"id":"3WpYSuvfry_-","executionInfo":{"status":"aborted","timestamp":1748546187641,"user_tz":-420,"elapsed":27157,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **Feature Selection**"],"metadata":{"id":"xVJT8BOcry_-"}},{"cell_type":"code","source":["import cudf\n","\n","# Ki·ªÉm tra n·∫øu X_TRAIN l√† cudf.DataFrame th√¨ m·ªõi chuy·ªÉn ƒë·ªïi\n","if isinstance(X_TRAIN, cudf.DataFrame):\n","    X_TRAIN_pd = X_TRAIN.to_pandas()\n","else:\n","    X_TRAIN_pd = X_TRAIN  # N·∫øu kh√¥ng ph·∫£i cudf th√¨ gi·ªØ nguy√™n\n","\n","# L·∫•y danh s√°ch c·ªôt s·ªë\n","numeric_features = X_TRAIN_pd.select_dtypes(include='number').columns\n","\n","# Th·ª±c hi·ªán scale d·ªØ li·ªáu\n","X_TRAIN_scaled = scaleData(X_TRAIN_pd, numeric_features)\n","\n","# N·∫øu ban ƒë·∫ßu l√† cudf, chuy·ªÉn ng∆∞·ª£c l·∫°i\n","if isinstance(X_TRAIN, cudf.DataFrame):\n","    X_TRAIN = cudf.from_pandas(X_TRAIN_scaled)\n","else:\n","    X_TRAIN = X_TRAIN_scaled\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:13:14.984850Z","iopub.execute_input":"2025-03-13T13:13:14.985197Z","iopub.status.idle":"2025-03-13T13:13:15.239584Z","shell.execute_reply.started":"2025-03-13T13:13:14.985158Z","shell.execute_reply":"2025-03-13T13:13:15.238826Z"},"id":"5odaHsoFry_-","executionInfo":{"status":"aborted","timestamp":1748546187643,"user_tz":-420,"elapsed":27155,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.feature_selection import RFE\n","\n","# Ki·ªÉm tra n·∫øu X_TRAIN l√† cudf.DataFrame th√¨ chuy·ªÉn v·ªÅ pandas, n·∫øu kh√¥ng th√¨ gi·ªØ nguy√™n\n","if hasattr(X_TRAIN, \"to_pandas\"):\n","    X_TRAIN_pd = X_TRAIN.to_pandas()\n","else:\n","    X_TRAIN_pd = X_TRAIN\n","\n","if hasattr(Y_TRAIN, \"to_pandas\"):\n","    Y_TRAIN_pd = Y_TRAIN.to_pandas()\n","else:\n","    Y_TRAIN_pd = Y_TRAIN\n","\n","# Ti·∫øn h√†nh ch·ªçn l·ªçc ƒë·∫∑c tr∆∞ng b·∫±ng RFE\n","clf = DecisionTreeClassifier(random_state=0)\n","rfe = RFE(estimator=clf, n_features_to_select=30, step=1)\n","rfe.fit(X_TRAIN_pd, Y_TRAIN_pd.astype(int))\n","\n","X_rfeTrain = rfe.transform(X_TRAIN_pd)\n","true = rfe.support_\n","rfecolindex_train = [i for i, x in enumerate(true) if x]\n","rfecolname_train = [numeric_features[i] for i in rfecolindex_train]\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:13:17.764535Z","iopub.execute_input":"2025-03-13T13:13:17.764903Z","iopub.status.idle":"2025-03-13T13:13:45.444220Z","shell.execute_reply.started":"2025-03-13T13:13:17.764871Z","shell.execute_reply":"2025-03-13T13:13:45.443211Z"},"id":"Eo1Avu8qry__","executionInfo":{"status":"aborted","timestamp":1748546187644,"user_tz":-420,"elapsed":27151,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["X_TRAIN.head()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T03:33:09.512093Z","iopub.execute_input":"2025-03-11T03:33:09.512465Z","iopub.status.idle":"2025-03-11T03:33:09.550561Z","shell.execute_reply.started":"2025-03-11T03:33:09.512436Z","shell.execute_reply":"2025-03-11T03:33:09.549549Z"},"id":"JAHRLdbVry__","executionInfo":{"status":"aborted","timestamp":1748546187653,"user_tz":-420,"elapsed":27156,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Ki·ªÉm tra n·∫øu X_TRAIN, Y_TRAIN ƒëang l√† cudf th√¨ chuy·ªÉn sang pandas\n","if isinstance(X_TRAIN, cudf.DataFrame):\n","    X_TRAIN = X_TRAIN.to_pandas()\n","if isinstance(Y_TRAIN, cudf.Series):\n","    Y_TRAIN = Y_TRAIN.to_pandas()\n","\n","# Chuy·ªÉn Y_TRAIN v·ªÅ ki·ªÉu int (n·∫øu ch∆∞a ƒë√∫ng)\n","Y_TRAIN = Y_TRAIN.astype(int)\n","\n","# Ki·ªÉm tra v√† x·ª≠ l√Ω d·ªØ li·ªáu NaN (n·∫øu c√≥)\n","X_TRAIN = X_TRAIN.fillna(X_TRAIN.mean())\n","\n","# Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt s·ªë (lo·∫°i b·ªè object n·∫øu c√≥)\n","X_TRAIN = X_TRAIN.select_dtypes(include=['number'])\n","\n","# Danh s√°ch c√°c c·ªôt s·ªë\n","numeric_features = X_TRAIN.columns\n","\n","# Kh·ªüi t·∫°o m√¥ h√¨nh Decision Tree\n","clf = DecisionTreeClassifier(random_state=0)\n","\n","# √Åp d·ª•ng Recursive Feature Elimination (RFE)\n","rfe = RFE(estimator=clf, n_features_to_select=30, step=1)\n","rfe.fit(X_TRAIN, Y_TRAIN)\n","\n","# Tr√≠ch xu·∫•t c√°c ƒë·∫∑c tr∆∞ng quan tr·ªçng\n","X_rfeTrain = rfe.transform(X_TRAIN)\n","true = rfe.support_\n","rfecolindex_train = [i for i, x in enumerate(true) if x]\n","rfecolname_train = list(numeric_features[i] for i in rfecolindex_train)\n","\n","# In ra danh s√°ch c√°c c·ªôt ƒë∆∞·ª£c ch·ªçn\n","print(\"C√°c c·ªôt ƒë∆∞·ª£c ch·ªçn:\", rfecolname_train)\n","\n","# List of selected important features\n","selected_features = ['flow_duration', 'Header_Length', 'Protocol Type', 'Duration', 'Rate', 'Srate', 'syn_flag_number', 'psh_flag_number', 'ack_flag_number', 'ack_count', 'syn_count', 'fin_count', 'urg_count', 'rst_count', 'HTTP', 'HTTPS', 'UDP', 'Tot sum', 'Min', 'Max', 'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue', 'Radius', 'Covariance', 'Variance', 'Weight']\n","\n","# Select important features from the training set\n","X_rfeTrain = X_TRAIN.loc[:, selected_features]\n","X_TEST = X_TEST.loc[:, selected_features]"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:13:57.190105Z","iopub.execute_input":"2025-03-13T13:13:57.190663Z","iopub.status.idle":"2025-03-13T13:14:24.287555Z","shell.execute_reply.started":"2025-03-13T13:13:57.190612Z","shell.execute_reply":"2025-03-13T13:14:24.286610Z"},"id":"IvvHKXmFry__","executionInfo":{"status":"aborted","timestamp":1748546187654,"user_tz":-420,"elapsed":27153,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["X_train, X_test, Y_train, Y_test = train_test_split(X_rfeTrain, Y_TRAIN, test_size=0.2, random_state=42)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:15:58.946254Z","iopub.execute_input":"2025-03-13T13:15:58.946599Z","iopub.status.idle":"2025-03-13T13:15:59.004886Z","shell.execute_reply.started":"2025-03-13T13:15:58.946567Z","shell.execute_reply":"2025-03-13T13:15:59.004050Z"},"id":"jnSFZc_Jry__","executionInfo":{"status":"aborted","timestamp":1748546187656,"user_tz":-420,"elapsed":27151,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Data set size\n","sizes = [X_train.shape[0], X_test.shape[0], Y_train.shape[0], Y_test.shape[0]]\n","labels = ['X_train', 'X_test', 'Y_train', 'Y_test']\n","\n","# Draw a column chart\n","plt.figure(figsize=(8, 6))\n","bars = plt.bar(labels, sizes, color=['blue', 'grey', 'blue', 'grey'])\n","plt.xlabel('Dataset')\n","plt.ylabel('Number of samples')\n","plt.title('Size of the datasets')\n","\n","# Display data at the top of the column\n","for bar, size in zip(bars, sizes):\n","    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(size), ha='center', va='bottom', fontsize=10)\n","\n","plt.show()"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:18:20.183771Z","iopub.execute_input":"2025-03-13T13:18:20.184406Z","iopub.status.idle":"2025-03-13T13:18:20.431887Z","shell.execute_reply.started":"2025-03-13T13:18:20.184370Z","shell.execute_reply":"2025-03-13T13:18:20.431017Z"},"id":"mXH5vE6Ery__","executionInfo":{"status":"aborted","timestamp":1748546187660,"user_tz":-420,"elapsed":27151,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["print(X_train.shape)\n","print(X_TEST.shape)\n","print(Y_train.shape)\n","print(Y_test.shape)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T13:19:51.619407Z","iopub.execute_input":"2025-03-13T13:19:51.620158Z","iopub.status.idle":"2025-03-13T13:19:51.625133Z","shell.execute_reply.started":"2025-03-13T13:19:51.620121Z","shell.execute_reply":"2025-03-13T13:19:51.624088Z"},"id":"xGQqgkGBrzAA","executionInfo":{"status":"aborted","timestamp":1748546187664,"user_tz":-420,"elapsed":27150,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n","from sklearn.impute import SimpleImputer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.feature_selection import SelectFromModel\n","\n","# ‚úÖ **1. Chia t·∫≠p train/test ƒë·∫£m b·∫£o ng·∫´u nhi√™n v√† ƒë·ªìng ƒë·ªÅu**\n","df_train, df_test = train_test_split(df_resampled, test_size=0.2, random_state=42, stratify=df_resampled['label'])\n","\n","# ‚úÖ **2. T√°ch nh√£n v√† ƒë·∫∑c tr∆∞ng**\n","Y_TRAIN = df_train['label'].copy()\n","Y_TEST = df_test['label'].copy()\n","X_TRAIN = df_train.drop('label', axis=1).copy()\n","X_TEST = df_test.drop('label', axis=1).copy()\n","\n","# ‚úÖ **3. Chuy·ªÉn ƒë·ªïi nh√£n th√†nh s·ªë**\n","label_mapping = {'BENIGN': 0, 'DDos': 1, 'DoS': 2, 'Mirai': 3,\n","                 'Spoofing': 4, 'Recon': 5, 'Web-based': 6, 'BruteForce': 7}\n","Y_TRAIN = Y_TRAIN.map(label_mapping).astype(int)\n","Y_TEST = Y_TEST.map(label_mapping).astype(int)\n","\n","# ‚úÖ **4. X·ª≠ l√Ω gi√° tr·ªã NaN (d√πng gi√° tr·ªã trung v·ªã ƒë·ªÉ tr√°nh ·∫£nh h∆∞·ªüng c·ªßa ngo·∫°i lai)**\n","imputer = SimpleImputer(strategy=\"median\")\n","X_TRAIN = pd.DataFrame(imputer.fit_transform(X_TRAIN), columns=X_TRAIN.columns)\n","X_TEST = pd.DataFrame(imputer.transform(X_TEST), columns=X_TEST.columns)\n","\n","# ‚úÖ **5. Scale d·ªØ li·ªáu ƒë√∫ng c√°ch (d√πng RobustScaler ƒë·ªÉ tr√°nh ·∫£nh h∆∞·ªüng c·ªßa gi√° tr·ªã ngo·∫°i lai)**\n","scaler = RobustScaler()\n","X_TRAIN = pd.DataFrame(scaler.fit_transform(X_TRAIN), columns=X_TRAIN.columns)\n","X_TEST = pd.DataFrame(scaler.transform(X_TEST), columns=X_TEST.columns)\n","\n","# ‚úÖ **6. Ch·ªçn l·ªçc ƒë·∫∑c tr∆∞ng t·ªët h∆°n b·∫±ng RandomForest**\n","selector = SelectFromModel(RandomForestClassifier(n_estimators=100, random_state=42), max_features=30)\n","selector.fit(X_TRAIN, Y_TRAIN)\n","\n","selected_features = X_TRAIN.columns[selector.get_support()]\n","print(f\"‚úÖ {len(selected_features)} Features Selected: {list(selected_features)}\")\n","\n","X_TRAIN = X_TRAIN[selected_features]\n","X_TEST = X_TEST[selected_features]\n","\n","# ‚úÖ **7. Ki·ªÉm tra l·∫°i k√≠ch th∆∞·ªõc t·∫≠p d·ªØ li·ªáu**\n","sizes = [X_TRAIN.shape[0], X_TEST.shape[0], Y_TRAIN.shape[0], Y_TEST.shape[0]]\n","labels = ['X_train', 'X_test', 'Y_train', 'Y_test']\n","\n","plt.figure(figsize=(8, 6))\n","bars = plt.bar(labels, sizes, color=['blue', 'grey', 'blue', 'grey'])\n","\n","# üè∑Ô∏è **Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng m·∫´u tr√™n bi·ªÉu ƒë·ªì**\n","for bar, size in zip(bars, sizes):\n","    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), str(size), ha='center', va='bottom', fontsize=10)\n","\n","plt.xlabel('Dataset')\n","plt.ylabel('Number of samples')\n","plt.title('Size of the datasets')\n","plt.show()\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T17:07:29.385491Z","iopub.execute_input":"2025-03-13T17:07:29.386199Z","iopub.status.idle":"2025-03-13T17:09:44.204626Z","shell.execute_reply.started":"2025-03-13T17:07:29.386165Z","shell.execute_reply":"2025-03-13T17:09:44.203682Z"},"id":"yIXPYuxbrzAA","executionInfo":{"status":"aborted","timestamp":1748546187666,"user_tz":-420,"elapsed":27148,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **Models**"],"metadata":{"id":"qo6kTUCyrzAA"}},{"cell_type":"code","source":["# pip install torch torchvision torchaudio"],"metadata":{"trusted":true,"id":"NOIORgG6rzAA","executionInfo":{"status":"aborted","timestamp":1748546187668,"user_tz":-420,"elapsed":27146,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **FT Trasformer**"],"metadata":{"id":"WhkjiONArzAA"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import StandardScaler\n","\n","# üõë Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU n·∫øu c·∫ßn\n","torch.cuda.empty_cache()\n","\n","# 1Ô∏è‚É£ Ki·ªÉm tra k√≠ch th∆∞·ªõc d·ªØ li·ªáu g·ªëc tr∆∞·ªõc khi chuy·ªÉn ƒë·ªïi\n","print(\"üîç Checking dataset shapes before processing...\")\n","print(\"X_TRAIN shape:\", X_TRAIN.shape)\n","print(\"Y_TRAIN shape:\", Y_TRAIN.shape)\n","print(\"X_TEST shape:\", X_TEST.shape)\n","print(\"Y_TEST shape:\", Y_TEST.shape)\n","\n","# 2Ô∏è‚É£ Ki·ªÉm tra v√† x·ª≠ l√Ω NaN (n·∫øu c√≥)\n","X_TRAIN = X_TRAIN.fillna(0)\n","X_TEST = X_TEST.fillna(0)\n","\n","# 3Ô∏è‚É£ Chu·∫©n h√≥a d·ªØ li·ªáu\n","scaler = StandardScaler()\n","X_train_np = scaler.fit_transform(X_TRAIN.values)  # ‚úÖ S·ª≠a: D√πng X_TRAIN ƒë√∫ng c√°ch\n","X_test_np = scaler.transform(X_TEST.values)\n","\n","# 4Ô∏è‚É£ Chuy·ªÉn nh√£n sang NumPy v√† ƒë·∫£m b·∫£o ƒë√∫ng ƒë·ªãnh d·∫°ng\n","Y_train_np = Y_TRAIN.values.squeeze()  # ‚úÖ S·ª≠a: D√πng .squeeze() ƒë·ªÉ lo·∫°i b·ªè chi·ªÅu th·ª´a\n","Y_test_np = Y_TEST.values.squeeze()\n","\n","# 5Ô∏è‚É£ Chuy·ªÉn d·ªØ li·ªáu th√†nh Tensor\n","X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n","Y_train_tensor = torch.tensor(Y_train_np, dtype=torch.long)\n","Y_test_tensor = torch.tensor(Y_test_np, dtype=torch.long)\n","\n","# 6Ô∏è‚É£ Ki·ªÉm tra k√≠ch th∆∞·ªõc sau khi chuy·ªÉn ƒë·ªïi\n","print(\"\\nüîç Checking tensor shapes after processing...\")\n","print(\"X_train_tensor shape:\", X_train_tensor.shape)\n","print(\"Y_train_tensor shape:\", Y_train_tensor.shape)\n","print(\"X_test_tensor shape:\", X_test_tensor.shape)\n","print(\"Y_test_tensor shape:\", Y_test_tensor.shape)\n","\n","# üöÄ Ki·ªÉm tra l·∫°i s·ªë l∆∞·ª£ng m·∫´u kh·ªõp nhau tr∆∞·ªõc khi ti·∫øp t·ª•c\n","assert X_train_tensor.shape[0] == Y_train_tensor.shape[0], \"‚ùå Mismatch between X_train and Y_train!\"\n","assert X_test_tensor.shape[0] == Y_test_tensor.shape[0], \"‚ùå Mismatch between X_test and Y_test!\"\n","\n","# 7Ô∏è‚É£ ƒê·ªãnh nghƒ©a m√¥ h√¨nh FT-Transformer\n","class FTTransformer(nn.Module):\n","    def __init__(self, num_features, num_classes, embed_dim=64, num_heads=4, num_blocks=3):\n","        super(FTTransformer, self).__init__()\n","\n","        # Embedding ƒë·∫∑c tr∆∞ng\n","        self.feature_embedding = nn.Linear(num_features, embed_dim)\n","\n","        # Positional Encoding\n","        self.positional_encoding = nn.Parameter(torch.randn(1, num_features, embed_dim))\n","\n","        # Transformer Encoder\n","        self.transformer_blocks = nn.TransformerEncoder(\n","            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, batch_first=True),\n","            num_layers=num_blocks\n","        )\n","\n","        # M·∫°ng ph√¢n lo·∫°i ƒë·∫ßu ra\n","        self.classifier = nn.Sequential(\n","            nn.Linear(embed_dim, 128),\n","            nn.GELU(),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        batch_size, num_features = x.shape\n","\n","        # Positional encoding ph√π h·ª£p k√≠ch th∆∞·ªõc\n","        pos_enc = self.positional_encoding[:, :num_features, :].expand(batch_size, -1, -1)\n","\n","        # √Åp d·ª•ng embedding v√† positional encoding\n","        x = self.feature_embedding(x).unsqueeze(1) + pos_enc\n","        x = self.transformer_blocks(x)  # Transformer Encoder\n","        x = x.mean(dim=1)  # L·∫•y trung b√¨nh theo feature\n","        x = self.classifier(x)  # D·ª± ƒëo√°n\n","        return x\n","\n","# 8Ô∏è‚É£ Kh·ªüi t·∫°o m√¥ h√¨nh, loss, optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_features = X_train_tensor.shape[1]\n","num_classes = len(np.unique(Y_train_np))\n","\n","model = FTTransformer(num_features, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n","\n","# 9Ô∏è‚É£ T·∫°o Dataloader\n","batch_size = 64\n","train_loader = DataLoader(TensorDataset(X_train_tensor, Y_train_tensor), batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_test_tensor, Y_test_tensor), batch_size=batch_size, shuffle=False)\n","\n","# üîç Ki·ªÉm tra l·∫°i batch size\n","print(f\"\\n‚úÖ Training batches: {len(train_loader)}, Test batches: {len(test_loader)}\")\n","\n","# üîü Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi Early Stopping\n","num_epochs = 50\n","best_test_acc = 0\n","patience = 5\n","no_improve_epochs = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_correct, train_total = 0, 0\n","    total_loss = 0.0\n","\n","    for X_batch, Y_batch in train_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","\n","        loss = criterion(outputs, Y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, predicted = torch.max(outputs, 1)\n","        train_total += Y_batch.size(0)\n","        train_correct += (predicted == Y_batch).sum().item()\n","        total_loss += loss.item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","    avg_train_loss = total_loss / len(train_loader)\n","\n","    # ƒê√°nh gi√° tr√™n t·∫≠p ki·ªÉm tra\n","    model.eval()\n","    test_correct, test_total = 0, 0\n","\n","    with torch.no_grad():\n","        for X_batch, Y_batch in test_loader:\n","            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","            outputs = model(X_batch)\n","            _, predicted = torch.max(outputs, 1)\n","            test_total += Y_batch.size(0)\n","            test_correct += (predicted == Y_batch).sum().item()\n","\n","    test_accuracy = 100 * test_correct / test_total\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_train_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n","\n","    # Early Stopping\n","    if test_accuracy > best_test_acc:\n","        best_test_acc = test_accuracy\n","        no_improve_epochs = 0\n","    else:\n","        no_improve_epochs += 1\n","        if no_improve_epochs >= patience:\n","            print(\"‚èπÔ∏è Early stopping activated!\")\n","            break\n","\n","# üîü ƒê√°nh gi√° cu·ªëi c√πng\n","print(f\"‚úÖ Final Test Accuracy: {best_test_acc:.2f}%\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T17:10:06.992117Z","iopub.execute_input":"2025-03-13T17:10:06.992487Z","iopub.status.idle":"2025-03-13T17:45:11.906747Z","shell.execute_reply.started":"2025-03-13T17:10:06.992456Z","shell.execute_reply":"2025-03-13T17:45:11.905850Z"},"id":"COytqTQTrzAA","executionInfo":{"status":"aborted","timestamp":1748546187673,"user_tz":-420,"elapsed":27147,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import gc\n","import torch\n","\n","def report_gpu():\n","    print(torch.cuda.list_gpu_processes())  # Hi·ªÉn th·ªã danh s√°ch c√°c ti·∫øn tr√¨nh GPU\n","    gc.collect()  # Thu h·ªìi b·ªô nh·ªõ r√°c\n","    torch.cuda.empty_cache()  # Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU\n","\n","# G·ªçi h√†m ƒë·ªÉ ki·ªÉm tra GPU\n","report_gpu()\n"],"metadata":{"trusted":true,"id":"bc4Bet-WrzAB","executionInfo":{"status":"aborted","timestamp":1748546187678,"user_tz":-420,"elapsed":27148,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import gc\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import label_binarize, StandardScaler\n","import torch.nn.functional as F\n","\n","# üñ•Ô∏è Ch·ªçn thi·∫øt b·ªã\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# üßπ Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU tr∆∞·ªõc khi ch·∫°y\n","def clear_gpu():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(torch.cuda.list_gpu_processes())\n","\n","clear_gpu()\n","\n","# üîÑ Chuy·ªÉn d·ªØ li·ªáu v·ªÅ thi·∫øt b·ªã\n","X_test_tensor = X_test_tensor.to(device)\n","Y_test_tensor = Y_test_tensor.to(device)\n","model.to(device)\n","\n","# üöÄ Ch·∫°y m√¥ h√¨nh tr√™n mini-batch\n","batch_size = 512\n","y_scores_list, y_pred_list, y_true_list = [], [], []\n","\n","model.eval()\n","with torch.no_grad():\n","    for i in range(0, len(X_test_tensor), batch_size):\n","        X_batch = X_test_tensor[i:i+batch_size]\n","        Y_batch = Y_test_tensor[i:i+batch_size]\n","\n","        with torch.amp.autocast(device_type='cuda'):\n","            logits = model(X_batch)\n","            y_scores_batch = F.softmax(logits, dim=1).cpu().numpy()\n","\n","        y_scores_list.append(y_scores_batch)\n","        y_pred_list.append(np.argmax(y_scores_batch, axis=1))\n","        y_true_list.append(Y_batch.cpu().numpy())\n","\n","# G·ªôp l·∫°i k·∫øt qu·∫£\n","y_scores = np.vstack(y_scores_list)\n","y_pred = np.concatenate(y_pred_list)\n","y_true = np.concatenate(y_true_list)\n","\n","# üìä Danh s√°ch nh√£n\n","selected_classes = ['DDos', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n","num_classes = len(selected_classes)\n","\n","# üìå V·∫Ω Confusion Matrix\n","def plot_confusion_matrix(y_true, y_pred, class_names):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# üìå C·∫£i ti·∫øn ROC-AUC (Gi·ªõi h·∫°n tr·ª•c X v√† Y)\n","def plot_roc_auc(y_true, y_scores, class_names):\n","    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n","    plt.figure(figsize=(8, 6))\n","\n","    for i in range(len(class_names)):\n","        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n","\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0, 0.02])  # Gi·ªõi h·∫°n X t·ª´ 0 - 0.02\n","    plt.ylim([0.5, 1])   # Gi·ªõi h·∫°n Y t·ª´ 0.5 - 1\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('ROC Curve (Zoomed In)')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","# üìå C·∫£i ti·∫øn PCA & t-SNE (3D) v·ªõi ch√∫ th√≠ch m√†u s·∫Øc\n","# H√†m v·∫Ω PCA v√† t-SNE 3D\n","def plot_tsne_pca_3d(X, y, class_names):\n","    sample_size = min(5000, len(X))  # Ch·ªçn t·ªëi ƒëa 5000 m·∫´u ƒë·ªÉ v·∫Ω\n","    idx = np.random.choice(len(X), sample_size, replace=False)\n","    X_sample = X[idx]\n","    y_sample = y[idx]\n","\n","    # Chu·∫©n h√≥a d·ªØ li·ªáu\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X_sample)\n","\n","    # Gi·∫£m chi·ªÅu v·ªõi PCA v√† t-SNE\n","    pca = PCA(n_components=3)\n","    tsne = TSNE(n_components=3, random_state=42)\n","\n","    X_pca = pca.fit_transform(X_scaled)\n","    X_tsne = tsne.fit_transform(X_scaled)\n","\n","    fig = plt.figure(figsize=(14, 6))\n","    cmap = plt.get_cmap(\"tab10\")  # B·∫£ng m√†u ph√¢n bi·ªát\n","    colors = cmap(np.linspace(0, 1, len(class_names)))\n","\n","    # V·∫Ω PCA 3D\n","    ax1 = fig.add_subplot(121, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax1.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax1.set_title('PCA 3D Visualization')\n","    ax1.set_xlabel('PCA 1')\n","    ax1.set_ylabel('PCA 2')\n","    ax1.set_zlabel('PCA 3')\n","    ax1.legend(loc='best')\n","\n","    # V·∫Ω t-SNE 3D\n","    ax2 = fig.add_subplot(122, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax2.scatter(X_tsne[mask, 0], X_tsne[mask, 1], X_tsne[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax2.set_title('t-SNE 3D Visualization')\n","    ax2.set_xlabel('t-SNE 1')\n","    ax2.set_ylabel('t-SNE 2')\n","    ax2.set_zlabel('t-SNE 3')\n","    ax2.legend(loc='best')\n","\n","    plt.show()\n","\n","\n","# üìå V·∫Ω Training & Validation Loss/Accuracy\n","def plot_training_curves(train_loss, val_loss, train_acc, val_acc):\n","    epochs = range(1, len(train_loss) + 1)\n","\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, train_loss, 'r', label='Train Loss')\n","    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title('Training & Validation Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, train_acc, 'r', label='Train Accuracy')\n","    plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.title('Training & Validation Accuracy')\n","    plt.legend()\n","\n","    plt.show()\n","\n","# üìä G·ªçi c√°c h√†m v·∫Ω bi·ªÉu ƒë·ªì\n","plot_confusion_matrix(y_true, y_pred, selected_classes)\n","plot_roc_auc(y_true, y_scores, selected_classes)\n","plot_tsne_pca_3d(X_test_tensor.cpu().numpy(), y_true, selected_classes)\n","\n","# üìå N·∫øu c√≥ d·ªØ li·ªáu l·ªãch s·ª≠ hu·∫•n luy·ªán, b·ªè comment d√≤ng d∆∞·ªõi ƒë·ªÉ v·∫Ω ƒë·ªì th·ªã hu·∫•n luy·ªán\n","#plot_training_curves(train_loss, val_loss, train_acc, val_acc)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T17:50:17.428976Z","iopub.execute_input":"2025-03-13T17:50:17.429308Z","iopub.status.idle":"2025-03-13T17:51:02.194183Z","shell.execute_reply.started":"2025-03-13T17:50:17.429280Z","shell.execute_reply":"2025-03-13T17:51:02.193304Z"},"id":"YlJeVoJ8rzAB","executionInfo":{"status":"aborted","timestamp":1748546187713,"user_tz":-420,"elapsed":27179,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **Tab Tranformer**"],"metadata":{"id":"ZSC5zGejrzAG"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# üü¢ 1Ô∏è‚É£ Load v√† chu·∫©n h√≥a d·ªØ li·ªáu\n","scaler = StandardScaler()\n","X_train_np = scaler.fit_transform(X_TRAIN.values)\n","X_test_np = scaler.transform(X_TEST.values)\n","\n","# üî¥ ƒê·∫£m b·∫£o l·∫•y ƒë√∫ng d·ªØ li·ªáu nh√£n (ch·ª© kh√¥ng ph·∫£i d·ªØ li·ªáu ƒë·∫ßu v√†o)\n","Y_train_np = Y_TRAIN.values  # Nh√£n ƒë√∫ng\n","Y_test_np = Y_TEST.values  # Nh√£n ƒë√∫ng\n","\n","# üü¢ 2Ô∏è‚É£ Chuy·ªÉn sang Tensor\n","X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n","\n","# üî¥ ƒê·∫£m b·∫£o `Y_train_tensor` c√≥ d·∫°ng `(batch_size,)`\n","Y_train_tensor = torch.tensor(Y_train_np, dtype=torch.long).squeeze()\n","Y_test_tensor = torch.tensor(Y_test_np, dtype=torch.long).squeeze()\n","\n","# üü¢ 3Ô∏è‚É£ ƒê·ªãnh nghƒ©a l·ªõp Transformer c·∫£i ti·∫øn\n","class TransformerBlock(nn.Module):\n","    def __init__(self, embed_dim, num_heads, dropout=0.1):\n","        super(TransformerBlock, self).__init__()\n","        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n","        self.norm1 = nn.LayerNorm(embed_dim)\n","        self.norm2 = nn.LayerNorm(embed_dim)\n","        self.ffn = nn.Sequential(\n","            nn.Linear(embed_dim, embed_dim * 2),\n","            nn.GELU(),\n","            nn.Linear(embed_dim * 2, embed_dim),\n","        )\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, x):\n","        attn_output, _ = self.attention(x, x, x)\n","        x = self.norm1(x + attn_output)\n","        ffn_output = self.ffn(x)\n","        x = self.norm2(x + ffn_output)\n","        return x\n","\n","# üü¢ 4Ô∏è‚É£ M√¥ h√¨nh TabTransformer\n","class TabTransformer(nn.Module):\n","    def __init__(self, num_features, num_classes, embed_dim=64, num_heads=4, num_blocks=3):\n","        super(TabTransformer, self).__init__()\n","        self.embedding = nn.Sequential(\n","            nn.Linear(num_features, embed_dim),\n","            nn.LayerNorm(embed_dim),\n","            nn.ReLU()\n","        )\n","        self.transformer_blocks = nn.Sequential(\n","            *[TransformerBlock(embed_dim, num_heads) for _ in range(num_blocks)]\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(embed_dim, 128),\n","            nn.GELU(),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = x.unsqueeze(0)  # Th√™m batch dimension\n","        x = self.transformer_blocks(x)\n","        x = x.squeeze(0)  # B·ªè batch dimension\n","        x = self.classifier(x)\n","        return x\n","\n","# üü¢ 5Ô∏è‚É£ Kh·ªüi t·∫°o m√¥ h√¨nh, loss, optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_features = X_train_tensor.shape[1]  # S·ªë ƒë·∫∑c tr∆∞ng ƒë·∫ßu v√†o\n","num_classes = len(np.unique(Y_train_np))  # S·ªë l·ªõp ƒë·∫ßu ra\n","\n","model = TabTransformer(num_features, num_classes).to(device)\n","\n","criterion = nn.CrossEntropyLoss()  # Kh√¥ng d√πng label smoothing ƒë·ªÉ tr√°nh l·ªói\n","optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n","\n","# üü¢ 6Ô∏è‚É£ Dataloader\n","train_loader = DataLoader(TensorDataset(X_train_tensor, Y_train_tensor), batch_size=64, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_test_tensor, Y_test_tensor), batch_size=64, shuffle=False)\n","\n","# üü¢ 7Ô∏è‚É£ Hu·∫•n luy·ªán m√¥ h√¨nh v·ªõi Early Stopping\n","num_epochs = 10\n","best_test_acc = 0\n","patience = 5\n","no_improve_epochs = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_correct, train_total = 0, 0\n","    total_loss = 0.0\n","\n","    for X_batch, Y_batch in train_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","\n","        # üî¥ ƒê·∫£m b·∫£o ƒë·∫ßu ra c√≥ shape [batch_size, num_classes]\n","        loss = criterion(outputs, Y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # üî¥ S·ª≠a l·ªói t√≠nh accuracy\n","        _, predicted = torch.max(outputs, 1)\n","        train_total += Y_batch.size(0)\n","        train_correct += (predicted == Y_batch).sum().item()\n","        total_loss += loss.item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","    avg_train_loss = total_loss / len(train_loader)\n","\n","    # üü¢ ƒê√°nh gi√° tr√™n t·∫≠p ki·ªÉm tra\n","    model.eval()\n","    test_correct, test_total = 0, 0\n","\n","    with torch.no_grad():\n","        for X_batch, Y_batch in test_loader:\n","            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","            outputs = model(X_batch)\n","            _, predicted = torch.max(outputs, 1)\n","            test_total += Y_batch.size(0)\n","            test_correct += (predicted == Y_batch).sum().item()\n","\n","    test_accuracy = 100 * test_correct / test_total\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_train_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n","\n","    # üü¢ Early Stopping\n","    if test_accuracy > best_test_acc:\n","        best_test_acc = test_accuracy\n","        no_improve_epochs = 0\n","    else:\n","        no_improve_epochs += 1\n","        if no_improve_epochs >= patience:\n","            print(\"‚èπÔ∏è Early stopping activated!\")\n","            break\n","\n","# üü¢ 8Ô∏è‚É£ ƒê√°nh gi√° cu·ªëi c√πng\n","print(f\"‚úÖ Final Test Accuracy: {best_test_acc:.2f}%\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T16:54:57.983554Z","iopub.execute_input":"2025-03-13T16:54:57.983928Z","iopub.status.idle":"2025-03-13T17:05:09.612045Z","shell.execute_reply.started":"2025-03-13T16:54:57.983883Z","shell.execute_reply":"2025-03-13T17:05:09.611031Z"},"id":"yaZspkDhrzAG","executionInfo":{"status":"aborted","timestamp":1748546187715,"user_tz":-420,"elapsed":27177,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import gc\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import label_binarize, StandardScaler\n","import torch.nn.functional as F\n","\n","# üñ•Ô∏è Ch·ªçn thi·∫øt b·ªã\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# üßπ Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU tr∆∞·ªõc khi ch·∫°y\n","def clear_gpu():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(torch.cuda.list_gpu_processes())\n","\n","clear_gpu()\n","\n","# üîÑ Chuy·ªÉn d·ªØ li·ªáu v·ªÅ thi·∫øt b·ªã\n","X_test_tensor = X_test_tensor.to(device)\n","Y_test_tensor = Y_test_tensor.to(device)\n","model.to(device)\n","\n","# üöÄ Ch·∫°y m√¥ h√¨nh tr√™n mini-batch\n","batch_size = 512\n","y_scores_list, y_pred_list, y_true_list = [], [], []\n","\n","model.eval()\n","with torch.no_grad():\n","    for i in range(0, len(X_test_tensor), batch_size):\n","        X_batch = X_test_tensor[i:i+batch_size]\n","        Y_batch = Y_test_tensor[i:i+batch_size]\n","\n","        with torch.amp.autocast(device_type='cuda'):\n","            logits = model(X_batch)\n","            y_scores_batch = F.softmax(logits, dim=1).cpu().numpy()\n","\n","        y_scores_list.append(y_scores_batch)\n","        y_pred_list.append(np.argmax(y_scores_batch, axis=1))\n","        y_true_list.append(Y_batch.cpu().numpy())\n","\n","# G·ªôp l·∫°i k·∫øt qu·∫£\n","y_scores = np.vstack(y_scores_list)\n","y_pred = np.concatenate(y_pred_list)\n","y_true = np.concatenate(y_true_list)\n","\n","# üìä Danh s√°ch nh√£n\n","selected_classes = ['DDos', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n","num_classes = len(selected_classes)\n","\n","# üìå V·∫Ω Confusion Matrix\n","def plot_confusion_matrix(y_true, y_pred, class_names):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","# üìå C·∫£i ti·∫øn ROC-AUC (Gi·ªõi h·∫°n tr·ª•c X v√† Y)\n","def plot_roc_auc(y_true, y_scores, class_names):\n","    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n","    plt.figure(figsize=(8, 6))\n","\n","    for i in range(len(class_names)):\n","        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n","\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0, 0.02])  # Gi·ªõi h·∫°n X t·ª´ 0 - 0.02\n","    plt.ylim([0.5, 1])   # Gi·ªõi h·∫°n Y t·ª´ 0.5 - 1\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('ROC Curve (Zoomed In)')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","# üìå C·∫£i ti·∫øn PCA & t-SNE (3D) v·ªõi ch√∫ th√≠ch m√†u s·∫Øc\n","# H√†m v·∫Ω PCA v√† t-SNE 3D\n","def plot_tsne_pca_3d(X, y, class_names):\n","    sample_size = min(5000, len(X))  # Ch·ªçn t·ªëi ƒëa 5000 m·∫´u ƒë·ªÉ v·∫Ω\n","    idx = np.random.choice(len(X), sample_size, replace=False)\n","    X_sample = X[idx]\n","    y_sample = y[idx]\n","\n","    # Chu·∫©n h√≥a d·ªØ li·ªáu\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X_sample)\n","\n","    # Gi·∫£m chi·ªÅu v·ªõi PCA v√† t-SNE\n","    pca = PCA(n_components=3)\n","    tsne = TSNE(n_components=3, random_state=42)\n","\n","    X_pca = pca.fit_transform(X_scaled)\n","    X_tsne = tsne.fit_transform(X_scaled)\n","\n","    fig = plt.figure(figsize=(14, 6))\n","    cmap = plt.get_cmap(\"tab10\")  # B·∫£ng m√†u ph√¢n bi·ªát\n","    colors = cmap(np.linspace(0, 1, len(class_names)))\n","\n","    # V·∫Ω PCA 3D\n","    ax1 = fig.add_subplot(121, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax1.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax1.set_title('PCA 3D Visualization')\n","    ax1.set_xlabel('PCA 1')\n","    ax1.set_ylabel('PCA 2')\n","    ax1.set_zlabel('PCA 3')\n","    ax1.legend(loc='best')\n","\n","    # V·∫Ω t-SNE 3D\n","    ax2 = fig.add_subplot(122, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax2.scatter(X_tsne[mask, 0], X_tsne[mask, 1], X_tsne[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax2.set_title('t-SNE 3D Visualization')\n","    ax2.set_xlabel('t-SNE 1')\n","    ax2.set_ylabel('t-SNE 2')\n","    ax2.set_zlabel('t-SNE 3')\n","    ax2.legend(loc='best')\n","\n","    plt.show()\n","\n","\n","# üìå V·∫Ω Training & Validation Loss/Accuracy\n","def plot_training_curves(train_loss, val_loss, train_acc, val_acc):\n","    epochs = range(1, len(train_loss) + 1)\n","\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, train_loss, 'r', label='Train Loss')\n","    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title('Training & Validation Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, train_acc, 'r', label='Train Accuracy')\n","    plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.title('Training & Validation Accuracy')\n","    plt.legend()\n","\n","    plt.show()\n","\n","# üìä G·ªçi c√°c h√†m v·∫Ω bi·ªÉu ƒë·ªì\n","plot_confusion_matrix(y_true, y_pred, selected_classes)\n","plot_roc_auc(y_true, y_scores, selected_classes)\n","plot_tsne_pca_3d(X_test_tensor.cpu().numpy(), y_true, selected_classes)\n","\n","# üìå N·∫øu c√≥ d·ªØ li·ªáu l·ªãch s·ª≠ hu·∫•n luy·ªán, b·ªè comment d√≤ng d∆∞·ªõi ƒë·ªÉ v·∫Ω ƒë·ªì th·ªã hu·∫•n luy·ªán\n","#plot_training_curves(train_loss, val_loss, train_acc, val_acc)\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T02:16:59.074691Z","iopub.execute_input":"2025-03-11T02:16:59.075083Z","iopub.status.idle":"2025-03-11T02:17:44.352331Z","shell.execute_reply.started":"2025-03-11T02:16:59.075052Z","shell.execute_reply":"2025-03-11T02:17:44.351428Z"},"id":"ENV9ALcDrzAH","executionInfo":{"status":"aborted","timestamp":1748546187717,"user_tz":-420,"elapsed":27174,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import numpy as np\n","import torch\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import label_binarize, StandardScaler\n","import torch.nn.functional as F\n","\n","# Chuy·ªÉn d·ªØ li·ªáu test v·ªÅ CPU ƒë·ªÉ x·ª≠ l√Ω\n","X_test_np = X_test_tensor.cpu().numpy()\n","Y_test_np = Y_test_tensor.cpu().numpy()\n","\n","# Ch·∫°y m√¥ h√¨nh ƒë·ªÉ l·∫•y d·ª± ƒëo√°n\n","model.eval()\n","with torch.no_grad():\n","    logits = model(X_test_tensor.to(device))\n","    y_scores = F.softmax(logits, dim=1).cpu().numpy()\n","    y_pred = np.argmax(y_scores, axis=1)\n","    y_true = Y_test_np\n","\n","selected_classes = ['DDos', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n","num_classes = len(selected_classes)\n","\n","def plot_confusion_matrix(y_true, y_pred, class_names):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.title('Confusion Matrix')\n","    plt.show()\n","\n","def plot_roc_auc(y_true, y_scores, class_names):\n","    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n","    plt.figure(figsize=(8, 6))\n","\n","    for i in range(len(class_names)):\n","        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n","\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('ROC Curve')\n","    plt.legend()\n","    plt.show()\n","\n","def plot_tsne_pca(X, y, class_names):\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X)\n","    pca = PCA(n_components=2)\n","    tsne = TSNE(n_components=2, random_state=42)\n","\n","    X_pca = pca.fit_transform(X_scaled)\n","    X_tsne = tsne.fit_transform(X_scaled)\n","\n","    plt.figure(figsize=(12, 5))\n","\n","    plt.subplot(1, 2, 1)\n","    scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap='viridis', alpha=0.7)\n","    plt.legend(handles=scatter.legend_elements()[0], labels=class_names, title=\"Classes\")\n","    plt.title('PCA Visualization')\n","\n","    plt.subplot(1, 2, 2)\n","    scatter = plt.scatter(X_tsne[:, 0], X_tsne[:, 1], c=y, cmap='viridis', alpha=0.7)\n","    plt.legend(handles=scatter.legend_elements()[0], labels=class_names, title=\"Classes\")\n","    plt.title('t-SNE Visualization')\n","\n","    plt.show()\n","\n","def plot_training_curves(train_loss, val_loss, train_acc, val_acc):\n","    epochs = range(1, len(train_loss) + 1)\n","\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, train_loss, 'r', label='Train Loss')\n","    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title('Training & Validation Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, train_acc, 'r', label='Train Accuracy')\n","    plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.title('Training & Validation Accuracy')\n","    plt.legend()\n","\n","    plt.show()\n","\n","plot_confusion_matrix(y_true, y_pred, selected_classes)\n","plot_roc_auc(y_true, y_scores, selected_classes)\n","plot_tsne_pca(X_test_np, y_true, selected_classes)\n","\n","# N·∫øu c√≥ d·ªØ li·ªáu l·ªãch s·ª≠ hu·∫•n luy·ªán:\n","#plot_training_curves(train_loss, val_loss, train_acc, val_acc)\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-04T09:21:11.361969Z","iopub.execute_input":"2025-03-04T09:21:11.362354Z","iopub.status.idle":"2025-03-04T09:21:25.103994Z","shell.execute_reply.started":"2025-03-04T09:21:11.362322Z","shell.execute_reply":"2025-03-04T09:21:25.102402Z"},"id":"_7anq2UHrzAH","executionInfo":{"status":"aborted","timestamp":1748546187721,"user_tz":-420,"elapsed":27174,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# XGBoost v√† MLP****"],"metadata":{"id":"tZ9dOGNBrzAI"}},{"cell_type":"code","source":["pip install torch-geometric"],"metadata":{"trusted":true,"id":"1J_a4skOrzAI","executionInfo":{"status":"aborted","timestamp":1748546187723,"user_tz":-420,"elapsed":27172,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import DataLoader, TensorDataset\n","import xgboost as xgb\n","\n","# üü¢ 1Ô∏è‚É£ Load v√† chu·∫©n h√≥a d·ªØ li·ªáu\n","def convert_to_dataframe(X):\n","    \"\"\" Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sang pandas DataFrame n·∫øu c·∫ßn \"\"\"\n","    if isinstance(X, torch.Tensor):\n","        X = X.cpu().numpy()  # Chuy·ªÉn t·ª´ Tensor -> NumPy\n","    if isinstance(X, np.ndarray):\n","        X = pd.DataFrame(X)  # Chuy·ªÉn t·ª´ NumPy -> DataFrame\n","    return X\n","\n","X_train = convert_to_dataframe(X_train)\n","X_test = convert_to_dataframe(X_test)\n","\n","# üõ† Ki·ªÉm tra xem X_train v√† X_test c√≥ d·ªØ li·ªáu kh√¥ng\n","if X_train.empty or X_test.empty:\n","    raise ValueError(\"‚ùå X_train ho·∫∑c X_test ƒëang b·ªã r·ªóng!\")\n","\n","# T√¨m c·ªôt chung gi·ªØa X_train v√† X_test\n","common_columns = X_train.columns.intersection(X_test.columns)\n","if len(common_columns) == 0:\n","    raise ValueError(\"‚ùå Kh√¥ng c√≥ c·ªôt chung n√†o gi·ªØa X_train v√† X_test!\")\n","X_train = X_train[common_columns]\n","X_test = X_test[common_columns]\n","\n","# üõ† X·ª≠ l√Ω gi√° tr·ªã NaN\n","X_train.fillna(0, inplace=True)\n","X_test.fillna(0, inplace=True)\n","\n","# üõ† ƒê·∫£m b·∫£o d·ªØ li·ªáu s·ªë\n","X_train = X_train.astype(np.float32)\n","X_test = X_test.astype(np.float32)\n","\n","# Chu·∫©n h√≥a d·ªØ li·ªáu\n","scaler = StandardScaler()\n","X_train_np = scaler.fit_transform(X_train)\n","X_test_np = scaler.transform(X_test)\n","\n","# Chuy·ªÉn ƒë·ªïi Y_train v√† Y_test th√†nh NumPy\n","def convert_labels(Y):\n","    \"\"\" Chuy·ªÉn ƒë·ªïi Y th√†nh NumPy \"\"\"\n","    if isinstance(Y, torch.Tensor):\n","        return Y.cpu().numpy()\n","    return np.array(Y)\n","\n","Y_train_np = convert_labels(Y_train)\n","Y_test_np = convert_labels(Y_test)\n","\n","# üü¢ 2Ô∏è‚É£ Hu·∫•n luy·ªán XGBoost\n","dtrain = xgb.DMatrix(X_train_np, label=Y_train_np)\n","dtest = xgb.DMatrix(X_test_np, label=Y_test_np)\n","\n","xgb_params = {\n","    'objective': 'multi:softprob',\n","    'num_class': len(np.unique(Y_train_np)),\n","    'max_depth': 6,\n","    'learning_rate': 0.1,\n","    'tree_method': 'hist',\n","    'eval_metric': 'mlogloss'\n","}\n","\n","xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=100)\n","\n","# üü¢ 3Ô∏è‚É£ Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ XGBoost\n","X_train_xgb = xgb_model.predict(dtrain)\n","X_test_xgb = xgb_model.predict(dtest)\n","\n","X_train_tensor = torch.tensor(X_train_xgb, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_xgb, dtype=torch.float32)\n","\n","Y_train_tensor = torch.tensor(Y_train_np, dtype=torch.long).squeeze()\n","Y_test_tensor = torch.tensor(Y_test_np, dtype=torch.long).squeeze()\n","\n","# üü¢ 4Ô∏è‚É£ ƒê·ªãnh nghƒ©a MLP\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, num_classes):\n","        super(MLP, self).__init__()\n","        self.fc = nn.Sequential(\n","            nn.Linear(input_dim, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(64, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.fc(x)\n","\n","# üü¢ 5Ô∏è‚É£ Kh·ªüi t·∫°o m√¥ h√¨nh, loss, optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_features = X_train_tensor.shape[1]\n","num_classes = len(np.unique(Y_train_np))\n","\n","mlp_model = MLP(num_features, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(mlp_model.parameters(), lr=0.001, weight_decay=1e-4)\n","\n","# üü¢ 6Ô∏è‚É£ DataLoader\n","train_loader = DataLoader(TensorDataset(X_train_tensor, Y_train_tensor), batch_size=64, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_test_tensor, Y_test_tensor), batch_size=64, shuffle=False)\n","\n","# üü¢ 7Ô∏è‚É£ Hu·∫•n luy·ªán MLP\n","num_epochs = 10\n","best_test_acc = 0\n","patience = 5\n","no_improve_epochs = 0\n","\n","for epoch in range(num_epochs):\n","    mlp_model.train()\n","    train_correct, train_total = 0, 0\n","    total_loss = 0.0\n","\n","    for X_batch, Y_batch in train_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        optimizer.zero_grad()\n","        outputs = mlp_model(X_batch)\n","\n","        loss = criterion(outputs, Y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, predicted = torch.max(outputs, 1)\n","        train_total += Y_batch.size(0)\n","        train_correct += (predicted == Y_batch).sum().item()\n","        total_loss += loss.item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","    avg_train_loss = total_loss / len(train_loader)\n","\n","    mlp_model.eval()\n","    test_correct, test_total = 0, 0\n","\n","    with torch.no_grad():\n","        for X_batch, Y_batch in test_loader:\n","            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","            outputs = mlp_model(X_batch)\n","            _, predicted = torch.max(outputs, 1)\n","            test_total += Y_batch.size(0)\n","            test_correct += (predicted == Y_batch).sum().item()\n","\n","    test_accuracy = 100 * test_correct / test_total\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_train_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n","\n","    if test_accuracy > best_test_acc:\n","        best_test_acc = test_accuracy\n","        no_improve_epochs = 0\n","    else:\n","        no_improve_epochs += 1\n","        if no_improve_epochs >= patience:\n","            print(\"‚èπÔ∏è Early stopping activated!\")\n","            break\n","\n","print(f\"‚úÖ Final Test Accuracy: {best_test_acc:.2f}%\")"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T02:27:25.248781Z","iopub.execute_input":"2025-03-11T02:27:25.249179Z","iopub.status.idle":"2025-03-11T02:28:29.768168Z","shell.execute_reply.started":"2025-03-11T02:27:25.249150Z","shell.execute_reply":"2025-03-11T02:28:29.767124Z"},"id":"RtvptgOBrzAI","executionInfo":{"status":"aborted","timestamp":1748546187724,"user_tz":-420,"elapsed":27169,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import gc\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import label_binarize, StandardScaler\n","import torch.nn.functional as F\n","\n","# üñ•Ô∏è Ch·ªçn thi·∫øt b·ªã\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# üßπ Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU tr∆∞·ªõc khi ch·∫°y\n","def clear_gpu():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(torch.cuda.list_gpu_processes())\n","\n","clear_gpu()\n","\n","# üöÄ Ch·∫°y m√¥ h√¨nh XGBoost\n","dtest = xgb.DMatrix(X_test_np)\n","y_scores_xgb = xgb_model.predict(dtest)\n","y_pred_xgb = np.argmax(y_scores_xgb, axis=1)\n","\n","# üöÄ Ch·∫°y m√¥ h√¨nh MLP\n","X_test_tensor = X_test_tensor.to(device)\n","Y_test_tensor = Y_test_tensor.to(device)\n","\n","mlp_model.eval()\n","y_scores_list, y_pred_list, y_true_list = [], [], []\n","\n","batch_size = 512\n","with torch.no_grad():\n","    for i in range(0, len(X_test_tensor), batch_size):\n","        X_batch = X_test_tensor[i:i+batch_size]\n","        Y_batch = Y_test_tensor[i:i+batch_size]\n","\n","        with torch.amp.autocast(device_type='cuda'):\n","            logits = mlp_model(X_batch)\n","            y_scores_batch = F.softmax(logits, dim=1).cpu().numpy()\n","\n","        y_scores_list.append(y_scores_batch)\n","        y_pred_list.append(np.argmax(y_scores_batch, axis=1))\n","        y_true_list.append(Y_batch.cpu().numpy())\n","\n","y_scores_mlp = np.vstack(y_scores_list)\n","y_pred_mlp = np.concatenate(y_pred_list)\n","y_true = np.concatenate(y_true_list)\n","\n","# üìä K·∫øt h·ª£p d·ª± ƒëo√°n c·ªßa XGBoost v√† MLP\n","y_scores_combined = (y_scores_xgb + y_scores_mlp) / 2\n","y_pred_combined = np.argmax(y_scores_combined, axis=1)\n","\n","# üìä Danh s√°ch nh√£n\n","selected_classes = ['DDos', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n","num_classes = len(selected_classes)\n","\n","# üìå V·∫Ω Confusion Matrix\n","def plot_confusion_matrix(y_true, y_pred, class_names):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.title('Confusion Matrix - Combined Model')\n","    plt.show()\n","\n","# üìå V·∫Ω ROC-AUC\n","def plot_roc_auc(y_true, y_scores, class_names):\n","    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n","    plt.figure(figsize=(8, 6))\n","\n","    for i in range(len(class_names)):\n","        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n","\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0, 0.02])  # Zoom v√†o v√πng nh·ªè ƒë·ªÉ d·ªÖ ph√¢n bi·ªát\n","    plt.ylim([0.5, 1])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('ROC Curve (Zoomed In) - Combined Model')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","# üìå V·∫Ω PCA & t-SNE 3D\n","def plot_tsne_pca_3d(X, y, class_names):\n","    sample_size = min(5000, len(X))\n","    idx = np.random.choice(len(X), sample_size, replace=False)\n","    X_sample = X[idx]\n","    y_sample = y[idx]\n","\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X_sample)\n","\n","    pca = PCA(n_components=3)\n","    tsne = TSNE(n_components=3, random_state=42)\n","\n","    X_pca = pca.fit_transform(X_scaled)\n","    X_tsne = tsne.fit_transform(X_scaled)\n","\n","    fig = plt.figure(figsize=(14, 6))\n","    cmap = plt.get_cmap(\"tab10\")\n","    colors = cmap(np.linspace(0, 1, len(class_names)))\n","\n","    ax1 = fig.add_subplot(121, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax1.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax1.set_title('PCA 3D - Combined Model')\n","    ax1.set_xlabel('PCA 1')\n","    ax1.set_ylabel('PCA 2')\n","    ax1.set_zlabel('PCA 3')\n","    ax1.legend(loc='best')\n","\n","    ax2 = fig.add_subplot(122, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax2.scatter(X_tsne[mask, 0], X_tsne[mask, 1], X_tsne[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax2.set_title('t-SNE 3D - Combined Model')\n","    ax2.set_xlabel('t-SNE 1')\n","    ax2.set_ylabel('t-SNE 2')\n","    ax2.set_zlabel('t-SNE 3')\n","    ax2.legend(loc='best')\n","\n","    plt.show()\n","\n","# üìä V·∫Ω k·∫øt qu·∫£ cho m√¥ h√¨nh k·∫øt h·ª£p\n","plot_confusion_matrix(y_true, y_pred_combined, selected_classes)\n","plot_roc_auc(y_true, y_scores_combined, selected_classes)\n","plot_tsne_pca_3d(X_test_np, y_true, selected_classes)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T02:28:36.481684Z","iopub.execute_input":"2025-03-11T02:28:36.482601Z","iopub.status.idle":"2025-03-11T02:29:21.941210Z","shell.execute_reply.started":"2025-03-11T02:28:36.482567Z","shell.execute_reply":"2025-03-11T02:29:21.940198Z"},"id":"9ZpWQJHnrzAI","executionInfo":{"status":"aborted","timestamp":1748546187725,"user_tz":-420,"elapsed":27166,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# SAINT****"],"metadata":{"id":"Eo8f9G-8rzAJ"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# üü¢ 1Ô∏è‚É£ Load v√† chu·∫©n h√≥a d·ªØ li·ªáu\n","scaler = StandardScaler()\n","X_train_np = scaler.fit_transform(X_train.values)\n","X_test_np = scaler.transform(X_test.values)\n","\n","# üî¥ ƒê·∫£m b·∫£o l·∫•y ƒë√∫ng d·ªØ li·ªáu nh√£n\n","Y_train_np = Y_train.values\n","Y_test_np = Y_test.values\n","\n","# üü¢ 2Ô∏è‚É£ Chuy·ªÉn sang Tensor\n","X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n","Y_train_tensor = torch.tensor(Y_train_np, dtype=torch.long).squeeze()\n","Y_test_tensor = torch.tensor(Y_test_np, dtype=torch.long).squeeze()\n","\n","# üü¢ 3Ô∏è‚É£ ƒê·ªãnh nghƒ©a SAINT Model\n","class SAINT(nn.Module):\n","    def __init__(self, num_features, num_classes, embed_dim=64, num_heads=4, num_blocks=3):\n","        super(SAINT, self).__init__()\n","\n","        self.embedding = nn.Sequential(\n","            nn.Linear(num_features, embed_dim),\n","            nn.LayerNorm(embed_dim),\n","            nn.ReLU()\n","        )\n","\n","        self.transformer_blocks = nn.ModuleList([\n","            nn.TransformerEncoderLayer(d_model=embed_dim, nhead=num_heads, dim_feedforward=embed_dim * 2, dropout=0.1, activation=\"gelu\")\n","            for _ in range(num_blocks)\n","        ])\n","\n","        self.classifier = nn.Sequential(\n","            nn.Linear(embed_dim, 128),\n","            nn.GELU(),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.embedding(x)\n","        x = x.unsqueeze(0)  # Th√™m batch dimension cho Transformer\n","        for block in self.transformer_blocks:\n","            x = block(x)\n","        x = x.squeeze(0)  # B·ªè batch dimension\n","        x = self.classifier(x)\n","        return x\n","\n","# üü¢ 4Ô∏è‚É£ Kh·ªüi t·∫°o m√¥ h√¨nh, loss, optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_features = X_train_tensor.shape[1]\n","num_classes = len(torch.unique(Y_train_tensor))  # ‚úÖ S·ª≠a l·ªói\n","\n","model = SAINT(num_features, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n","\n","# üü¢ 5Ô∏è‚É£ Dataloader\n","train_loader = DataLoader(TensorDataset(X_train_tensor, Y_train_tensor), batch_size=64, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_test_tensor, Y_test_tensor), batch_size=64, shuffle=False)\n","\n","# üü¢ 6Ô∏è‚É£ Hu·∫•n luy·ªán v·ªõi Early Stopping\n","num_epochs = 10\n","best_test_acc = 0\n","patience = 5\n","no_improve_epochs = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_correct, train_total = 0, 0\n","    total_loss = 0.0\n","\n","    for X_batch, Y_batch in train_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","        loss = criterion(outputs, Y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, predicted = torch.max(outputs, 1)\n","        train_total += Y_batch.size(0)\n","        train_correct += (predicted == Y_batch).sum().item()\n","        total_loss += loss.item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","    avg_train_loss = total_loss / len(train_loader)\n","\n","    # üü¢ ƒê√°nh gi√° tr√™n t·∫≠p ki·ªÉm tra\n","    model.eval()\n","    test_correct, test_total = 0, 0\n","\n","    with torch.no_grad():\n","        for X_batch, Y_batch in test_loader:\n","            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","            outputs = model(X_batch)\n","            _, predicted = torch.max(outputs, 1)\n","            test_total += Y_batch.size(0)\n","            test_correct += (predicted == Y_batch).sum().item()\n","\n","    test_accuracy = 100 * test_correct / test_total\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_train_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n","\n","    # üü¢ Early Stopping\n","    if test_accuracy > best_test_acc:\n","        best_test_acc = test_accuracy\n","        no_improve_epochs = 0\n","    else:\n","        no_improve_epochs += 1\n","        if no_improve_epochs >= patience:\n","            print(\"‚èπÔ∏è Early stopping activated!\")\n","            break\n","\n","# üü¢ 7Ô∏è‚É£ ƒê√°nh gi√° cu·ªëi c√πng\n","print(f\"‚úÖ Final Test Accuracy: {best_test_acc:.2f}%\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T02:29:55.737537Z","iopub.execute_input":"2025-03-11T02:29:55.738295Z","iopub.status.idle":"2025-03-11T02:35:04.859013Z","shell.execute_reply.started":"2025-03-11T02:29:55.738256Z","shell.execute_reply":"2025-03-11T02:35:04.858136Z"},"id":"y9hIOtPRrzAJ","executionInfo":{"status":"aborted","timestamp":1748546187726,"user_tz":-420,"elapsed":27163,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import label_binarize, StandardScaler\n","import torch.nn.functional as F\n","\n","# üñ•Ô∏è Ch·ªçn thi·∫øt b·ªã\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# üöÄ D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm tra\n","model.eval()\n","y_scores_list, y_pred_list, y_true_list = [], [], []\n","\n","with torch.no_grad():\n","    for X_batch, Y_batch in test_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        outputs = model(X_batch)\n","        y_scores_batch = F.softmax(outputs, dim=1).cpu().numpy()\n","\n","        y_scores_list.append(y_scores_batch)\n","        y_pred_list.append(np.argmax(y_scores_batch, axis=1))\n","        y_true_list.append(Y_batch.cpu().numpy())\n","\n","y_scores = np.vstack(y_scores_list)\n","y_pred = np.concatenate(y_pred_list)\n","y_true = np.concatenate(y_true_list)\n","\n","# üìä Danh s√°ch nh√£n\n","selected_classes = [f\"Class {i}\" for i in range(num_classes)]\n","\n","# üìå V·∫Ω Confusion Matrix\n","def plot_confusion_matrix(y_true, y_pred, class_names):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.title('Confusion Matrix - SAINT Model')\n","    plt.show()\n","\n","# üìå V·∫Ω ROC-AUC\n","def plot_roc_auc(y_true, y_scores, class_names):\n","    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n","    plt.figure(figsize=(8, 6))\n","\n","    for i in range(len(class_names)):\n","        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n","\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('ROC Curve - SAINT Model')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","# üìå V·∫Ω PCA & t-SNE 3D\n","def plot_tsne_pca_3d(X, y, class_names):\n","    sample_size = min(5000, len(X))\n","    idx = np.random.choice(len(X), sample_size, replace=False)\n","    X_sample = X[idx]\n","    y_sample = y[idx]\n","\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X_sample)\n","\n","    pca = PCA(n_components=3)\n","    tsne = TSNE(n_components=3, random_state=42)\n","\n","    X_pca = pca.fit_transform(X_scaled)\n","    X_tsne = tsne.fit_transform(X_scaled)\n","\n","    fig = plt.figure(figsize=(14, 6))\n","    cmap = plt.get_cmap(\"tab10\")\n","    colors = cmap(np.linspace(0, 1, len(class_names)))\n","\n","    ax1 = fig.add_subplot(121, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax1.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax1.set_title('PCA 3D - SAINT Model')\n","    ax1.set_xlabel('PCA 1')\n","    ax1.set_ylabel('PCA 2')\n","    ax1.set_zlabel('PCA 3')\n","    ax1.legend(loc='best')\n","\n","    ax2 = fig.add_subplot(122, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax2.scatter(X_tsne[mask, 0], X_tsne[mask, 1], X_tsne[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax2.set_title('t-SNE 3D - SAINT Model')\n","    ax2.set_xlabel('t-SNE 1')\n","    ax2.set_ylabel('t-SNE 2')\n","    ax2.set_zlabel('t-SNE 3')\n","    ax2.legend(loc='best')\n","\n","    plt.show()\n","\n","# üìä V·∫Ω k·∫øt qu·∫£ cho m√¥ h√¨nh SAINT\n","plot_confusion_matrix(y_true, y_pred, selected_classes)\n","plot_roc_auc(y_true, y_scores, selected_classes)\n","plot_tsne_pca_3d(X_test_np, y_true, selected_classes)\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T02:35:08.591415Z","iopub.execute_input":"2025-03-11T02:35:08.591736Z","iopub.status.idle":"2025-03-11T02:35:54.706619Z","shell.execute_reply.started":"2025-03-11T02:35:08.591708Z","shell.execute_reply":"2025-03-11T02:35:54.705675Z"},"id":"KGJGFco-rzAJ","executionInfo":{"status":"aborted","timestamp":1748546187728,"user_tz":-420,"elapsed":27160,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# DANet (Dual Attention Network)****"],"metadata":{"id":"WiPHc3qTrzAK"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from torch.utils.data import DataLoader, TensorDataset\n","from sklearn.preprocessing import StandardScaler\n","\n","# Ki·ªÉm tra GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","torch.cuda.empty_cache()\n","\n","# Chu·∫©n h√≥a d·ªØ li·ªáu\n","scaler = StandardScaler()\n","X_train_np = scaler.fit_transform(X_train.values)\n","X_test_np = scaler.transform(X_test.values)\n","\n","Y_train_np = Y_train.values\n","Y_test_np = Y_test.values\n","\n","# Chuy·ªÉn th√†nh Tensor\n","X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n","Y_train_tensor = torch.tensor(Y_train_np, dtype=torch.long)\n","Y_test_tensor = torch.tensor(Y_test_np, dtype=torch.long)\n","\n","# T·∫°o DataLoader\n","batch_size = 64\n","train_loader = DataLoader(TensorDataset(X_train_tensor, Y_train_tensor), batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_test_tensor, Y_test_tensor), batch_size=batch_size, shuffle=False)\n","\n","# ‚úÖ ƒê·ªãnh nghƒ©a m√¥ h√¨nh DANet\n","class DANet(nn.Module):\n","    def __init__(self, num_features, num_classes, embed_dim=64):\n","        super(DANet, self).__init__()\n","\n","        self.feature_embedding = nn.Linear(num_features, embed_dim)\n","\n","        # Spatial Attention\n","        self.spatial_attention = nn.Sequential(\n","            nn.Linear(embed_dim, embed_dim),\n","            nn.Tanh(),\n","            nn.Linear(embed_dim, 1)\n","        )\n","\n","        # Channel Attention\n","        self.channel_attention = nn.Sequential(\n","            nn.Linear(embed_dim, embed_dim),\n","            nn.ReLU(),\n","            nn.Linear(embed_dim, embed_dim),\n","            nn.Sigmoid()\n","        )\n","\n","        # Classifier\n","        self.classifier = nn.Sequential(\n","            nn.Linear(embed_dim, 128),\n","            nn.ReLU(),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.feature_embedding(x)  # (batch_size, embed_dim)\n","\n","        # Spatial Attention\n","        attn_weights = self.spatial_attention(x)  # (batch_size, 1)\n","        attn_weights = torch.softmax(attn_weights, dim=1)\n","        x = x * attn_weights  # √Åp d·ª•ng attention weights\n","\n","        # Channel Attention\n","        channel_attn = self.channel_attention(x)  # (batch_size, embed_dim)\n","        x = x * channel_attn  # √Åp d·ª•ng attention weights\n","\n","        x = torch.flatten(x, start_dim=1)  # ƒê·∫£m b·∫£o ƒë√∫ng k√≠ch th∆∞·ªõc\n","\n","        x = self.classifier(x)  # (batch_size, num_classes)\n","        return x\n","\n","# ‚úÖ Kh·ªüi t·∫°o m√¥ h√¨nh\n","num_features = X_train_tensor.shape[1]\n","num_classes = len(np.unique(Y_train_np))\n","\n","model = DANet(num_features, num_classes).to(device)\n","\n","# ‚úÖ ƒê·ªãnh nghƒ©a loss v√† optimizer\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-4)\n","\n","# ‚úÖ Training loop v·ªõi Early Stopping\n","num_epochs = 50\n","best_test_acc = 0\n","patience = 5\n","no_improve_epochs = 0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_correct, train_total = 0, 0\n","    total_loss = 0.0\n","\n","    for X_batch, Y_batch in train_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)  # (batch_size, num_classes)\n","\n","        loss = criterion(outputs, Y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, predicted = torch.max(outputs, 1)\n","        train_total += Y_batch.size(0)\n","        train_correct += (predicted == Y_batch).sum().item()\n","        total_loss += loss.item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","    avg_train_loss = total_loss / len(train_loader)\n","\n","    # ‚úÖ ƒê√°nh gi√° tr√™n t·∫≠p test\n","    model.eval()\n","    test_correct, test_total = 0, 0\n","\n","    with torch.no_grad():\n","        for X_batch, Y_batch in test_loader:\n","            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","            outputs = model(X_batch)\n","            _, predicted = torch.max(outputs, 1)\n","            test_total += Y_batch.size(0)\n","            test_correct += (predicted == Y_batch).sum().item()\n","\n","    test_accuracy = 100 * test_correct / test_total\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_train_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n","\n","    # ‚úÖ Early Stopping\n","    if test_accuracy > best_test_acc:\n","        best_test_acc = test_accuracy\n","        no_improve_epochs = 0\n","    else:\n","        no_improve_epochs += 1\n","        if no_improve_epochs >= patience:\n","            print(\"‚èπÔ∏è Early stopping activated!\")\n","            break\n","\n","# ‚úÖ K·∫øt qu·∫£ cu·ªëi c√πng\n","print(f\"‚úÖ Final Test Accuracy: {best_test_acc:.2f}%\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T05:34:49.655747Z","iopub.execute_input":"2025-03-13T05:34:49.656110Z","iopub.status.idle":"2025-03-13T05:39:55.682539Z","shell.execute_reply.started":"2025-03-13T05:34:49.656083Z","shell.execute_reply":"2025-03-13T05:39:55.681503Z"},"id":"Xv75nuf8rzAK","executionInfo":{"status":"aborted","timestamp":1748546187732,"user_tz":-420,"elapsed":27160,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import label_binarize, StandardScaler\n","import torch.nn.functional as F\n","\n","# üñ•Ô∏è Ch·ªçn thi·∫øt b·ªã\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# üöÄ D·ª± ƒëo√°n tr√™n t·∫≠p ki·ªÉm tra\n","model.eval()\n","y_scores_list, y_pred_list, y_true_list = [], [], []\n","\n","with torch.no_grad():\n","    for X_batch, Y_batch in test_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        outputs = model(X_batch)\n","        y_scores_batch = F.softmax(outputs, dim=1).cpu().numpy()\n","\n","        y_scores_list.append(y_scores_batch)\n","        y_pred_list.append(np.argmax(y_scores_batch, axis=1))\n","        y_true_list.append(Y_batch.cpu().numpy())\n","\n","y_scores = np.vstack(y_scores_list)\n","y_pred = np.concatenate(y_pred_list)\n","y_true = np.concatenate(y_true_list)\n","\n","# üìä Danh s√°ch nh√£n\n","selected_classes = [f\"Class {i}\" for i in range(num_classes)]\n","\n","# ‚úÖ V·∫Ω Confusion Matrix\n","def plot_confusion_matrix(y_true, y_pred, class_names):\n","    cm = confusion_matrix(y_true, y_pred)\n","\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.title('Confusion Matrix - DANet Model')\n","    plt.show()\n","\n","# ‚úÖ V·∫Ω ROC-AUC (Ch·ªâ v·∫Ω n·∫øu s·ªë l·ªõp > 1)\n","def plot_roc_auc(y_true, y_scores, class_names):\n","    if len(class_names) < 2:\n","        print(\"‚ö†Ô∏è Kh√¥ng th·ªÉ v·∫Ω ROC-AUC v·ªõi ch·ªâ m·ªôt l·ªõp duy nh·∫•t!\")\n","        return\n","\n","    y_true_bin = label_binarize(y_true, classes=np.arange(len(class_names)))\n","    plt.figure(figsize=(8, 6))\n","\n","    for i in range(len(class_names)):\n","        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n","\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0, 1])\n","    plt.ylim([0, 1])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title('ROC Curve - DANet Model')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","# ‚úÖ V·∫Ω PCA & t-SNE 3D (Ch·ªâ v·∫Ω n·∫øu s·ªë feature > 3)\n","def plot_tsne_pca_3d(X, y, class_names):\n","    if X.shape[1] < 3:\n","        print(\"‚ö†Ô∏è Kh√¥ng th·ªÉ v·∫Ω PCA/t-SNE 3D v√¨ s·ªë feature qu√° √≠t!\")\n","        return\n","\n","    sample_size = min(5000, len(X))\n","    idx = np.random.choice(len(X), sample_size, replace=False)\n","    X_sample = X[idx]\n","    y_sample = y[idx]\n","\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X_sample)\n","\n","    pca = PCA(n_components=3)\n","    tsne = TSNE(n_components=3, random_state=42)\n","\n","    X_pca = pca.fit_transform(X_scaled)\n","    X_tsne = tsne.fit_transform(X_scaled)\n","\n","    fig = plt.figure(figsize=(14, 6))\n","    cmap = plt.get_cmap(\"tab10\")\n","    colors = cmap(np.linspace(0, 1, len(class_names)))\n","\n","    # üìå PCA 3D\n","    ax1 = fig.add_subplot(121, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax1.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax1.set_title('PCA 3D - DANet Model')\n","    ax1.set_xlabel('PCA 1')\n","    ax1.set_ylabel('PCA 2')\n","    ax1.set_zlabel('PCA 3')\n","    ax1.legend(loc='best')\n","\n","    # üìå t-SNE 3D\n","    ax2 = fig.add_subplot(122, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax2.scatter(X_tsne[mask, 0], X_tsne[mask, 1], X_tsne[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax2.set_title('t-SNE 3D - DANet Model')\n","    ax2.set_xlabel('t-SNE 1')\n","    ax2.set_ylabel('t-SNE 2')\n","    ax2.set_zlabel('t-SNE 3')\n","    ax2.legend(loc='best')\n","\n","    plt.show()\n","\n","# üìä V·∫Ω k·∫øt qu·∫£ cho m√¥ h√¨nh DANet\n","plot_confusion_matrix(y_true, y_pred, selected_classes)\n","plot_roc_auc(y_true, y_scores, selected_classes)\n","plot_tsne_pca_3d(X_test_np, y_true, selected_classes)"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T02:38:46.719263Z","iopub.execute_input":"2025-03-11T02:38:46.719632Z","iopub.status.idle":"2025-03-11T02:39:31.242339Z","shell.execute_reply.started":"2025-03-11T02:38:46.719582Z","shell.execute_reply":"2025-03-11T02:39:31.241428Z"},"id":"FYCRSiRyrzAK","executionInfo":{"status":"aborted","timestamp":1748546187791,"user_tz":-420,"elapsed":27215,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# TEST C√ÅC M√î H√åNH ****"],"metadata":{"id":"hamm5wl7rzAL"}},{"cell_type":"code","source":["import pandas as pd\n","import torch\n","from sklearn.preprocessing import StandardScaler\n","import joblib  # D√πng ƒë·ªÉ load scaler n·∫øu ƒë√£ l∆∞u tr∆∞·ªõc ƒë√≥\n","\n","# üîπ Danh s√°ch c·ªôt ƒë∆∞·ª£c ch·ªçn\n","selected_features = [\n","    'flow_duration', 'Header_Length', 'Protocol Type', 'Duration', 'Rate', 'Srate',\n","    'syn_flag_number', 'psh_flag_number', 'ack_count', 'syn_count', 'fin_count',\n","    'urg_count', 'rst_count', 'HTTP', 'HTTPS', 'DNS', 'SSH', 'Tot sum', 'Min', 'Max',\n","    'AVG', 'Std', 'Tot size', 'IAT', 'Number', 'Magnitue', 'Radius',\n","    'Covariance', 'Variance', 'Weight'\n","]\n","\n","# üîπ ƒê·ªçc d·ªØ li·ªáu test\n","file_path = \"/kaggle/input/cic-iot-2023/part-00024-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv\"\n","df_test = pd.read_csv(file_path)\n","\n","# üîπ Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt s·ªë\n","df_test = df_test.select_dtypes(include=[\"number\"])\n","\n","# üîπ Ki·ªÉm tra c·ªôt b·ªã thi·∫øu v√† ƒëi·ªÅn gi√° tr·ªã trung b√¨nh n·∫øu c·∫ßn\n","missing_cols = [col for col in selected_features if col not in df_test.columns]\n","if missing_cols:\n","    print(f\"‚ö†Ô∏è D·ªØ li·ªáu ki·ªÉm tra thi·∫øu c√°c c·ªôt: {missing_cols}. S·∫Ω ƒëi·ªÅn gi√° tr·ªã trung b√¨nh!\")\n","    for col in missing_cols:\n","        df_test[col] = df_test.mean()  # ƒêi·ªÅn b·∫±ng gi√° tr·ªã trung b√¨nh\n","\n","df_test = df_test[selected_features]\n","\n","# üîπ Load scaler n·∫øu ch∆∞a c√≥\n","try:\n","    scaler\n","except NameError:\n","    print(\"‚ö†Ô∏è Ch∆∞a c√≥ scaler, ƒëang t·∫£i t·ª´ file...\")\n","    scaler = joblib.load(\"scaler.pkl\")  # Load scaler ƒë√£ hu·∫•n luy·ªán t·ª´ tr∆∞·ªõc\n","\n","# üîπ Ki·ªÉm tra scaler ƒë√£ hu·∫•n luy·ªán ch∆∞a\n","if not hasattr(scaler, \"mean_\"):\n","    raise ValueError(\"‚ö†Ô∏è B·∫°n ch∆∞a hu·∫•n luy·ªán `scaler`! H√£y ch·∫°y `scaler.fit(data_train)` tr∆∞·ªõc.\")\n","\n","# üîπ Chu·∫©n h√≥a d·ªØ li·ªáu test\n","X_new_scaled = scaler.transform(df_test)\n","\n","# üîπ Chuy·ªÉn th√†nh DataFrame ƒë·ªÉ gi·ªØ t√™n c·ªôt\n","X_new_scaled_df = pd.DataFrame(X_new_scaled, columns=selected_features)\n","\n","# üîπ Chuy·ªÉn th√†nh Tensor\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","X_new_tensor = torch.tensor(X_new_scaled_df.values, dtype=torch.float32, device=device)\n","\n","# üîπ Ki·ªÉm tra model ƒë√£ ƒë∆∞·ª£c load ch∆∞a\n","try:\n","    model\n","except NameError:\n","    print(\"‚ö†Ô∏è Ch∆∞a c√≥ model, ƒëang t·∫£i t·ª´ file...\")\n","    model = torch.load(\"model.pth\", map_location=device)  # Load m√¥ h√¨nh t·ª´ file\n","    model.eval()\n","\n","# üîπ ƒê·∫£m b·∫£o d·ªØ li·ªáu ƒë·∫ßu v√†o c√≥ ƒë√∫ng s·ªë chi·ªÅu\n","expected_input_size = model.feature_embedding.weight.shape[0]  # S·ªë feature c·ªßa m√¥ h√¨nh\n","if X_new_tensor.shape[1] != expected_input_size:\n","    raise ValueError(f\"‚ùå S·ªë l∆∞·ª£ng features kh√¥ng kh·ªõp v·ªõi model! C·∫ßn {expected_input_size}, nh∆∞ng d·ªØ li·ªáu test c√≥ {X_new_tensor.shape[1]}\")\n","\n","# üîπ ƒê√°nh gi√° model (gi·∫£m batch size ƒë·ªÉ tr√°nh l·ªói GPU)\n","batch_size = 512  # Gi·∫£m batch size ƒë·ªÉ tr√°nh l·ªói CUDA\n","num_batches = (X_new_tensor.shape[0] // batch_size) + 1\n","\n","predicted_labels = []\n","model.eval()\n","with torch.no_grad():\n","    for i in range(num_batches):\n","        batch = X_new_tensor[i * batch_size: (i + 1) * batch_size]\n","        if batch.shape[0] == 0:\n","            continue\n","        outputs = model(batch)\n","        _, predicted = torch.max(outputs, 1)\n","        predicted_labels.extend(predicted.cpu().numpy())\n","\n","# üîπ L∆∞u k·∫øt qu·∫£ v√†o file CSV\n","df_test[\"Predicted_Label\"] = predicted_labels\n","df_test.to_csv(\"predicted_results_fixed.csv\", index=False)\n","\n","print(\"‚úÖ K·∫øt qu·∫£ d·ª± ƒëo√°n ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o predicted_results_fixed.csv!\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-13T17:51:41.293834Z","iopub.execute_input":"2025-03-13T17:51:41.294422Z","iopub.status.idle":"2025-03-13T17:51:42.350553Z","shell.execute_reply.started":"2025-03-13T17:51:41.294378Z","shell.execute_reply":"2025-03-13T17:51:42.349369Z"},"id":"YaaTTHh9rzAL","executionInfo":{"status":"aborted","timestamp":1748546187793,"user_tz":-420,"elapsed":27213,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import torch\n","print(torch.cuda.is_available())  # Ph·∫£i tr·∫£ v·ªÅ True\n","print(torch.cuda.device_count())  # S·ªë l∆∞·ª£ng GPU\n","print(torch.cuda.get_device_name(0))  # T√™n GPU\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-11T03:43:53.328087Z","iopub.execute_input":"2025-03-11T03:43:53.329059Z","iopub.status.idle":"2025-03-11T03:43:53.335141Z","shell.execute_reply.started":"2025-03-11T03:43:53.329020Z","shell.execute_reply":"2025-03-11T03:43:53.334208Z"},"id":"GaYpJZwprzAL","executionInfo":{"status":"aborted","timestamp":1748546187794,"user_tz":-420,"elapsed":27210,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# **GATv2**"],"metadata":{"id":"mObT4acfrzAM"}},{"cell_type":"code","source":["pip install torch-geometric\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T04:28:22.417393Z","iopub.execute_input":"2025-03-09T04:28:22.417743Z","iopub.status.idle":"2025-03-09T04:28:32.293294Z","shell.execute_reply.started":"2025-03-09T04:28:22.417706Z","shell.execute_reply":"2025-03-09T04:28:32.292234Z"},"id":"MYkbX38arzAM","executionInfo":{"status":"aborted","timestamp":1748546187796,"user_tz":-420,"elapsed":27208,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.preprocessing import StandardScaler\n","from torch.utils.data import DataLoader, TensorDataset\n","import xgboost as xgb\n","\n","# üü¢ 1Ô∏è‚É£ Load v√† chu·∫©n h√≥a d·ªØ li·ªáu\n","def convert_to_dataframe(X):\n","    \"\"\" Chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu sang pandas DataFrame n·∫øu c·∫ßn \"\"\"\n","    if isinstance(X, torch.Tensor):\n","        X = X.cpu().numpy()  # Chuy·ªÉn t·ª´ Tensor -> NumPy\n","    if isinstance(X, np.ndarray):\n","        X = pd.DataFrame(X)  # Chuy·ªÉn t·ª´ NumPy -> DataFrame\n","    return X\n","\n","X_train = convert_to_dataframe(X_train)\n","X_test = convert_to_dataframe(X_test)\n","\n","# üõ† Ki·ªÉm tra xem X_train v√† X_test c√≥ d·ªØ li·ªáu kh√¥ng\n","if X_train.empty or X_test.empty:\n","    raise ValueError(\"‚ùå X_train ho·∫∑c X_test ƒëang b·ªã r·ªóng!\")\n","\n","# T√¨m c·ªôt chung gi·ªØa X_train v√† X_test\n","common_columns = X_train.columns.intersection(X_test.columns)\n","if len(common_columns) == 0:\n","    raise ValueError(\"‚ùå Kh√¥ng c√≥ c·ªôt chung n√†o gi·ªØa X_train v√† X_test!\")\n","X_train = X_train[common_columns]\n","X_test = X_test[common_columns]\n","\n","# üõ† X·ª≠ l√Ω gi√° tr·ªã NaN\n","X_train.fillna(0, inplace=True)\n","X_test.fillna(0, inplace=True)\n","\n","# üõ† ƒê·∫£m b·∫£o d·ªØ li·ªáu s·ªë\n","X_train = X_train.astype(np.float32)\n","X_test = X_test.astype(np.float32)\n","\n","# Chu·∫©n h√≥a d·ªØ li·ªáu\n","scaler = StandardScaler()\n","X_train_np = scaler.fit_transform(X_train)\n","X_test_np = scaler.transform(X_test)\n","\n","# Chuy·ªÉn ƒë·ªïi Y_train v√† Y_test th√†nh NumPy\n","def convert_labels(Y):\n","    \"\"\" Chuy·ªÉn ƒë·ªïi Y th√†nh NumPy \"\"\"\n","    if isinstance(Y, torch.Tensor):\n","        return Y.cpu().numpy()\n","    return np.array(Y)\n","\n","Y_train_np = convert_labels(Y_train)\n","Y_test_np = convert_labels(Y_test)\n","\n","# üü¢ 2Ô∏è‚É£ Hu·∫•n luy·ªán XGBoost\n","dtrain = xgb.DMatrix(X_train_np, label=Y_train_np)\n","dtest = xgb.DMatrix(X_test_np, label=Y_test_np)\n","\n","xgb_params = {\n","    'objective': 'multi:softprob',\n","    'num_class': len(np.unique(Y_train_np)),\n","    'max_depth': 6,\n","    'learning_rate': 0.1,\n","    'tree_method': 'hist',\n","    'eval_metric': 'mlogloss'\n","}\n","\n","xgb_model = xgb.train(xgb_params, dtrain, num_boost_round=100)\n","\n","# üü¢ 3Ô∏è‚É£ Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ XGBoost\n","X_train_xgb = xgb_model.predict(dtrain)\n","X_test_xgb = xgb_model.predict(dtest)\n","\n","X_train_tensor = torch.tensor(X_train_xgb, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test_xgb, dtype=torch.float32)\n","\n","Y_train_tensor = torch.tensor(Y_train_np, dtype=torch.long).squeeze()\n","Y_test_tensor = torch.tensor(Y_test_np, dtype=torch.long).squeeze()\n","\n","# üü¢ 4Ô∏è‚É£ ƒê·ªãnh nghƒ©a MLP\n","class MLP(nn.Module):\n","    def __init__(self, input_dim, num_classes):\n","        super(MLP, self).__init__()\n","        self.fc = nn.Sequential(\n","            nn.Linear(input_dim, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(128, 64),\n","            nn.ReLU(),\n","            nn.Dropout(0.3),\n","            nn.Linear(64, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        return self.fc(x)\n","\n","# üü¢ 5Ô∏è‚É£ Kh·ªüi t·∫°o m√¥ h√¨nh, loss, optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","num_features = X_train_tensor.shape[1]\n","num_classes = len(np.unique(Y_train_np))\n","\n","mlp_model = MLP(num_features, num_classes).to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.AdamW(mlp_model.parameters(), lr=0.001, weight_decay=1e-4)\n","\n","# üü¢ 6Ô∏è‚É£ DataLoader\n","train_loader = DataLoader(TensorDataset(X_train_tensor, Y_train_tensor), batch_size=64, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_test_tensor, Y_test_tensor), batch_size=64, shuffle=False)\n","\n","# üü¢ 7Ô∏è‚É£ Hu·∫•n luy·ªán MLP\n","num_epochs = 10\n","best_test_acc = 0\n","patience = 5\n","no_improve_epochs = 0\n","\n","for epoch in range(num_epochs):\n","    mlp_model.train()\n","    train_correct, train_total = 0, 0\n","    total_loss = 0.0\n","\n","    for X_batch, Y_batch in train_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        optimizer.zero_grad()\n","        outputs = mlp_model(X_batch)\n","\n","        loss = criterion(outputs, Y_batch)\n","        loss.backward()\n","        optimizer.step()\n","\n","        _, predicted = torch.max(outputs, 1)\n","        train_total += Y_batch.size(0)\n","        train_correct += (predicted == Y_batch).sum().item()\n","        total_loss += loss.item()\n","\n","    train_accuracy = 100 * train_correct / train_total\n","    avg_train_loss = total_loss / len(train_loader)\n","\n","    mlp_model.eval()\n","    test_correct, test_total = 0, 0\n","\n","    with torch.no_grad():\n","        for X_batch, Y_batch in test_loader:\n","            X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","            outputs = mlp_model(X_batch)\n","            _, predicted = torch.max(outputs, 1)\n","            test_total += Y_batch.size(0)\n","            test_correct += (predicted == Y_batch).sum().item()\n","\n","    test_accuracy = 100 * test_correct / test_total\n","\n","    print(f\"Epoch [{epoch + 1}/{num_epochs}] - Loss: {avg_train_loss:.4f} - Train Acc: {train_accuracy:.2f}% - Test Acc: {test_accuracy:.2f}%\")\n","\n","    if test_accuracy > best_test_acc:\n","        best_test_acc = test_accuracy\n","        no_improve_epochs = 0\n","    else:\n","        no_improve_epochs += 1\n","        if no_improve_epochs >= patience:\n","            print(\"‚èπÔ∏è Early stopping activated!\")\n","            break\n","\n","print(f\"‚úÖ Final Test Accuracy: {best_test_acc:.2f}%\")\n"],"metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-09T05:47:08.936474Z","iopub.execute_input":"2025-03-09T05:47:08.936840Z","iopub.status.idle":"2025-03-09T05:47:09.011656Z","shell.execute_reply.started":"2025-03-09T05:47:08.936813Z","shell.execute_reply":"2025-03-09T05:47:09.010331Z"},"id":"Z9triDDtrzAM","executionInfo":{"status":"aborted","timestamp":1748546187799,"user_tz":-420,"elapsed":27206,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import gc\n","import torch\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from mpl_toolkits.mplot3d import Axes3D\n","from sklearn.metrics import confusion_matrix, roc_curve, auc\n","from sklearn.decomposition import PCA\n","from sklearn.manifold import TSNE\n","from sklearn.preprocessing import label_binarize, StandardScaler\n","import torch.nn.functional as F\n","\n","# üñ•Ô∏è Ch·ªçn thi·∫øt b·ªã\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# üßπ Gi·∫£i ph√≥ng b·ªô nh·ªõ GPU tr∆∞·ªõc khi ch·∫°y\n","def clear_gpu():\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    print(torch.cuda.list_gpu_processes())\n","\n","clear_gpu()\n","\n","# üöÄ Ch·∫°y m√¥ h√¨nh XGBoost\n","dtest = xgb.DMatrix(X_test_np)\n","y_scores_xgb = xgb_model.predict(dtest)\n","y_pred_xgb = np.argmax(y_scores_xgb, axis=1)\n","\n","# üöÄ Ch·∫°y m√¥ h√¨nh MLP\n","X_test_tensor = X_test_tensor.to(device)\n","Y_test_tensor = Y_test_tensor.to(device)\n","\n","mlp_model.eval()\n","y_scores_list, y_pred_list, y_true_list = [], [], []\n","\n","batch_size = 512\n","with torch.no_grad():\n","    for i in range(0, len(X_test_tensor), batch_size):\n","        X_batch = X_test_tensor[i:i+batch_size]\n","        Y_batch = Y_test_tensor[i:i+batch_size]\n","\n","        with torch.amp.autocast(device_type='cuda'):\n","            logits = mlp_model(X_batch)\n","            y_scores_batch = F.softmax(logits, dim=1).cpu().numpy()\n","\n","        y_scores_list.append(y_scores_batch)\n","        y_pred_list.append(np.argmax(y_scores_batch, axis=1))\n","        y_true_list.append(Y_batch.cpu().numpy())\n","\n","y_scores_mlp = np.vstack(y_scores_list)\n","y_pred_mlp = np.concatenate(y_pred_list)\n","y_true = np.concatenate(y_true_list)\n","\n","# üìä Danh s√°ch nh√£n\n","selected_classes = ['DDos', 'DoS', 'Recon', 'Spoofing', 'BruteForce', 'Web-based', 'Mirai', 'BENIGN']\n","num_classes = len(selected_classes)\n","\n","# üìå V·∫Ω Confusion Matrix\n","def plot_confusion_matrix(y_true, y_pred, class_names, model_name):\n","    cm = confusion_matrix(y_true, y_pred)\n","    plt.figure(figsize=(8, 6))\n","    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n","    plt.xlabel('Predicted')\n","    plt.ylabel('Actual')\n","    plt.title(f'Confusion Matrix - {model_name}')\n","    plt.show()\n","\n","# üìå V·∫Ω ROC-AUC\n","def plot_roc_auc(y_true, y_scores, class_names, model_name):\n","    y_true_bin = label_binarize(y_true, classes=range(len(class_names)))\n","    plt.figure(figsize=(8, 6))\n","\n","    for i in range(len(class_names)):\n","        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_scores[:, i])\n","        roc_auc = auc(fpr, tpr)\n","        plt.plot(fpr, tpr, label=f'{class_names[i]} (AUC = {roc_auc:.2f})')\n","\n","    plt.plot([0, 1], [0, 1], 'k--')\n","    plt.xlim([0, 0.02])  # Zoom v√†o v√πng nh·ªè ƒë·ªÉ d·ªÖ ph√¢n bi·ªát\n","    plt.ylim([0.5, 1])\n","    plt.xlabel('False Positive Rate')\n","    plt.ylabel('True Positive Rate')\n","    plt.title(f'ROC Curve (Zoomed In) - {model_name}')\n","    plt.legend()\n","    plt.grid(True)\n","    plt.show()\n","\n","# üìå V·∫Ω PCA & t-SNE 3D\n","def plot_tsne_pca_3d(X, y, class_names, model_name):\n","    sample_size = min(5000, len(X))\n","    idx = np.random.choice(len(X), sample_size, replace=False)\n","    X_sample = X[idx]\n","    y_sample = y[idx]\n","\n","    scaler = StandardScaler()\n","    X_scaled = scaler.fit_transform(X_sample)\n","\n","    pca = PCA(n_components=3)\n","    tsne = TSNE(n_components=3, random_state=42)\n","\n","    X_pca = pca.fit_transform(X_scaled)\n","    X_tsne = tsne.fit_transform(X_scaled)\n","\n","    fig = plt.figure(figsize=(14, 6))\n","    cmap = plt.get_cmap(\"tab10\")\n","    colors = cmap(np.linspace(0, 1, len(class_names)))\n","\n","    ax1 = fig.add_subplot(121, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax1.scatter(X_pca[mask, 0], X_pca[mask, 1], X_pca[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax1.set_title(f'PCA 3D - {model_name}')\n","    ax1.set_xlabel('PCA 1')\n","    ax1.set_ylabel('PCA 2')\n","    ax1.set_zlabel('PCA 3')\n","    ax1.legend(loc='best')\n","\n","    ax2 = fig.add_subplot(122, projection='3d')\n","    for i, class_name in enumerate(class_names):\n","        mask = (y_sample == i)\n","        ax2.scatter(X_tsne[mask, 0], X_tsne[mask, 1], X_tsne[mask, 2],\n","                    color=colors[i], label=class_name, alpha=0.7)\n","    ax2.set_title(f't-SNE 3D - {model_name}')\n","    ax2.set_xlabel('t-SNE 1')\n","    ax2.set_ylabel('t-SNE 2')\n","    ax2.set_zlabel('t-SNE 3')\n","    ax2.legend(loc='best')\n","\n","    plt.show()\n","\n","# üìå V·∫Ω ƒë·ªì th·ªã Loss & Accuracy\n","def plot_training_curves(train_loss, val_loss, train_acc, val_acc, model_name):\n","    epochs = range(1, len(train_loss) + 1)\n","\n","    plt.figure(figsize=(12, 5))\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epochs, train_loss, 'r', label='Train Loss')\n","    plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.title(f'Training & Validation Loss - {model_name}')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(epochs, train_acc, 'r', label='Train Accuracy')\n","    plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.title(f'Training & Validation Accuracy - {model_name}')\n","    plt.legend()\n","\n","    plt.show()\n","\n","# üìä V·∫Ω k·∫øt qu·∫£ cho t·ª´ng m√¥ h√¨nh\n","plot_confusion_matrix(y_true, y_pred_xgb, selected_classes, \"XGBoost\")\n","plot_confusion_matrix(y_true, y_pred_mlp, selected_classes, \"MLP\")\n","\n","plot_roc_auc(y_true, y_scores_xgb, selected_classes, \"XGBoost\")\n","plot_roc_auc(y_true, y_scores_mlp, selected_classes, \"MLP\")\n","\n","plot_tsne_pca_3d(X_test_np, y_true, selected_classes, \"XGBoost\")\n","plot_tsne_pca_3d(X_test_tensor.cpu().numpy(), y_true, selected_classes, \"MLP\")\n"],"metadata":{"trusted":true,"id":"UmejLBherzAN","executionInfo":{"status":"aborted","timestamp":1748546187825,"user_tz":-420,"elapsed":27228,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","# Chu·∫©n h√≥a d·ªØ li·ªáu\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","Y_train_tensor = torch.tensor(Y_train, dtype=torch.long)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","Y_test_tensor = torch.tensor(Y_test, dtype=torch.long)\n","\n","num_features = X_train.shape[1]\n","num_classes = len(np.unique(Y_train))\n","\n","class FeatureTokenizer(nn.Module):\n","    def __init__(self, num_features, embed_dim):\n","        super().__init__()\n","        self.linear = nn.Linear(1, embed_dim)\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n","\n","    def forward(self, x):\n","        x = x.unsqueeze(-1)\n","        x = self.linear(x)\n","        cls_tokens = self.cls_token.expand(x.size(0), -1, -1)\n","        return torch.cat((cls_tokens, x), dim=1)\n","\n","class TransformerEncoderBlock(nn.Module):\n","    def __init__(self, embed_dim, num_heads, dropout=0.2):\n","        super().__init__()\n","        self.attention = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout)\n","        self.norm1 = nn.LayerNorm(embed_dim)\n","        self.norm2 = nn.LayerNorm(embed_dim)\n","        self.ffn = nn.Sequential(\n","            nn.Linear(embed_dim, embed_dim * 2),\n","            nn.GELU(),\n","            nn.Linear(embed_dim * 2, embed_dim),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        attn_output, _ = self.attention(x, x, x)\n","        x = self.norm1(x + attn_output)\n","        x = self.norm2(x + self.ffn(x))\n","        return x\n","\n","class FTTransformer(nn.Module):\n","    def __init__(self, num_features, num_classes, embed_dim=64, num_heads=4, num_blocks=3):\n","        super().__init__()\n","        self.tokenizer = FeatureTokenizer(num_features, embed_dim)\n","        self.transformer_blocks = nn.Sequential(\n","            *[TransformerEncoderBlock(embed_dim, num_heads) for _ in range(num_blocks)]\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Linear(embed_dim, 128),\n","            nn.BatchNorm1d(128),\n","            nn.GELU(),\n","            nn.Linear(128, num_classes)\n","        )\n","\n","    def forward(self, x):\n","        x = self.tokenizer(x)\n","        x = x.permute(1, 0, 2)\n","        x = self.transformer_blocks(x)\n","        return self.classifier(x[0])\n","\n","model = FTTransformer(num_features, num_classes)\n","criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n","optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)\n","\n","train_loader = DataLoader(TensorDataset(X_train_tensor, Y_train_tensor), batch_size=32, shuffle=True)\n","test_loader = DataLoader(TensorDataset(X_test_tensor, Y_test_tensor), batch_size=32, shuffle=False)\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","\n","num_epochs = 20\n","for epoch in range(num_epochs):\n","    model.train()\n","    total_loss, correct, total = 0, 0, 0\n","    for X_batch, Y_batch in train_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(X_batch)\n","        loss = criterion(outputs, Y_batch)\n","        loss.backward()\n","        optimizer.step()\n","        total_loss += loss.item()\n","        correct += (outputs.argmax(1) == Y_batch).sum().item()\n","        total += Y_batch.size(0)\n","    train_accuracy = 100 * correct / total\n","    scheduler.step(total_loss)\n","    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {total_loss:.4f} - Train Acc: {train_accuracy:.2f}%\")\n","\n","model.eval()\n","correct, total = 0, 0\n","with torch.no_grad():\n","    for X_batch, Y_batch in test_loader:\n","        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n","        outputs = model(X_batch)\n","        correct += (outputs.argmax(1) == Y_batch).sum().item()\n","        total += Y_batch.size(0)\n","test_accuracy = 100 * correct / total\n","print(f\"Final Test Accuracy: {test_accuracy:.2f}%\")"],"metadata":{"trusted":true,"id":"zpoX31RQrzAN","executionInfo":{"status":"aborted","timestamp":1748546187827,"user_tz":-420,"elapsed":27226,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# 5.Gaussian Mixture Model (GMM)"],"metadata":{"id":"xOgn4y4-rzAN"}},{"cell_type":"code","source":["# Train Gaussian Mixture Model (GMM)\n","gmm_model = GaussianMixture(n_components=len(np.unique(Y_train)), random_state=42)\n","gmm_model.fit(X_train)\n","\n","# Predict and evaluate (GMM requires predicting the class)\n","gmm_predictions = gmm_model.predict(X_test)\n","print(\"GMM Accuracy:\", accuracy_score(Y_test, gmm_predictions))\n","print(\"GMM Classification Report:\\n\", classification_report(Y_test, gmm_predictions))"],"metadata":{"trusted":true,"id":"Su9sZErErzAN","executionInfo":{"status":"aborted","timestamp":1748546187829,"user_tz":-420,"elapsed":27223,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["# 6.Gaussian Naive Bayes (GNB)"],"metadata":{"id":"-06U1hwCrzAO"}},{"cell_type":"code","source":["# Train Gaussian Naive Bayes (GNB)\n","gnb_model = GaussianNB()\n","gnb_model.fit(X_train, Y_train)\n","\n","# Predict and evaluate\n","gnb_predictions = gnb_model.predict(X_test)\n","print(\"GNB Accuracy:\", accuracy_score(Y_test, gnb_predictions))\n","print(\"GNB Classification Report:\\n\", classification_report(Y_test, gnb_predictions))"],"metadata":{"trusted":true,"id":"cH-7ghPMrzAO","executionInfo":{"status":"aborted","timestamp":1748546187831,"user_tz":-420,"elapsed":27221,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Conv1D, LSTM, Bidirectional, Dropout, MaxPooling1D, Flatten\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Gi·∫£ s·ª≠ X_train, X_test, Y_train, Y_test ƒë√£ ƒë∆∞·ª£c chia v√† chu·∫©n h√≥a tr∆∞·ªõc ƒë√≥\n","\n","# ƒê·ªãnh d·∫°ng l·∫°i d·ªØ li·ªáu cho CNN & LSTM n·∫øu ch∆∞a l√†m\n","X_train = np.expand_dims(X_train, axis=2)  # ƒê·∫£m b·∫£o d·ªØ li·ªáu c√≥ d·∫°ng (s·ªë m·∫´u, s·ªë ƒë·∫∑c tr∆∞ng, 1)\n","X_test = np.expand_dims(X_test, axis=2)\n","\n","# X√¢y d·ª±ng m√¥ h√¨nh DeepHybrid-IDS (CNN + BiLSTM)\n","model = Sequential([\n","    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n","    MaxPooling1D(pool_size=2),\n","    Conv1D(filters=128, kernel_size=3, activation='relu'),\n","    Bidirectional(LSTM(64, return_sequences=True)),  # BiLSTM ƒë·∫ßu ti√™n gi·ªØ nguy√™n chu·ªói ƒë·∫ßu ra\n","    Bidirectional(LSTM(32)),  # LSTM th·ª© hai ch·ªâ gi·ªØ ƒë·∫ßu ra cu·ªëi\n","    Flatten(),\n","    Dense(64, activation='relu'),\n","    Dropout(0.5),\n","    Dense(len(np.unique(Y_train)), activation='softmax')  # S·ªë l·ªõp ƒë·∫ßu ra ph√π h·ª£p v·ªõi s·ªë nh√£n\n","])\n","\n","# Compile m√¥ h√¨nh\n","model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n","\n","# Hu·∫•n luy·ªán m√¥ h√¨nh\n","model.fit(X_train, Y_train, validation_data=(X_test, Y_test), epochs=20, batch_size=32)\n","\n","# D·ª± ƒëo√°n v√† ƒë√°nh gi√° m√¥ h√¨nh\n","y_pred = np.argmax(model.predict(X_test), axis=1)\n","\n","# ƒê√°nh gi√° m√¥ h√¨nh\n","print(\"DeepHybrid-IDS Accuracy:\", accuracy_score(Y_test, y_pred))\n","print(\"DeepHybrid-IDS Classification Report:\\n\", classification_report(Y_test, y_pred, target_names=label_encoder.classes_))\n"],"metadata":{"trusted":true,"id":"6-pYgbbKrzAO","executionInfo":{"status":"aborted","timestamp":1748546187835,"user_tz":-420,"elapsed":27221,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":[],"metadata":{"id":"EMFJ3kROrzAO"}},{"cell_type":"markdown","source":["# **Evaluate and Choose Best Model**"],"metadata":{"id":"V0Kxq1MCrzAO"}},{"cell_type":"code","source":["# Create a dictionary to store accuracy of each model\n","model_accuracies = {\n","    \"Random Forest\": accuracy_score(Y_test, rf_predictions),\n","    \"Gradient Boosting\": accuracy_score(Y_test, gb_predictions),\n","    \"CNN\": cnn_accuracy,\n","    \"SVM\": accuracy_score(Y_test, svm_predictions),\n","    \"GMM\": accuracy_score(Y_test, gmm_predictions),\n","    \"GNB\": accuracy_score(Y_test, gnb_predictions)\n","}\n","\n","# Find the model with the highest accuracy\n","best_model_name = max(model_accuracies, key=model_accuracies.get)\n","best_accuracy = model_accuracies[best_model_name]\n","\n","print(f\"The best model is: {best_model_name} with accuracy: {best_accuracy * 100:.2f}%\")\n"],"metadata":{"trusted":true,"id":"DHoF6m7lrzAO","executionInfo":{"status":"aborted","timestamp":1748546187836,"user_tz":-420,"elapsed":27218,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":["#  Save the Best Model"],"metadata":{"id":"OpcwVFk3rzAP"}},{"cell_type":"code","source":["# Save the best performing model\n","if best_model_name == \"Random Forest\":\n","    joblib.dump(rf_model, 'best_rf_model.pkl')\n","elif best_model_name == \"Gradient Boosting\":\n","    joblib.dump(gb_model, 'best_gb_model.pkl')\n","elif best_model_name == \"CNN\":\n","    cnn_model.save('best_cnn_model.h5')\n","elif best_model_name == \"SVM\":\n","    joblib.dump(svm_model, 'best_svm_model.pkl')\n","elif best_model_name == \"GMM\":\n","    joblib.dump(gmm_model, 'best_gmm_model.pkl')\n","elif best_model_name == \"GNB\":\n","    joblib.dump(gnb_model, 'best_gnb_model.pkl')\n","\n","print(f\"Best model saved: {best_model_name}\")\n"],"metadata":{"trusted":true,"id":"TcbuLe0LrzAP","executionInfo":{"status":"aborted","timestamp":1748546187838,"user_tz":-420,"elapsed":27215,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["joblib.dump(cnn_model, 'best_cnn_model.pkl')"],"metadata":{"trusted":true,"id":"08-q9xsPrzAP","executionInfo":{"status":"aborted","timestamp":1748546187843,"user_tz":-420,"elapsed":27216,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["import pickle\n","# Save the entire model as .h5\n","cnn_model.save('cnn_model.h5')\n","print(\"CNN model saved as 'cnn_model.h5'\")\n","\n","# Save the model architecture (JSON) and weights separately for .pkl\n","model_json = cnn_model.to_json()\n","with open('cnn_model.json', 'w') as json_file:\n","    json_file.write(model_json)\n","\n","# Save weights with the correct filename extension\n","cnn_model.save_weights('cnn_model.weights.h5')\n","print(\"CNN model weights saved as 'cnn_model.weights.h5'\")\n","\n","# Save both JSON and weights path in a .pkl file\n","with open('cnn_model.pkl', 'wb') as f:\n","    pickle.dump({'model_json': 'cnn_model.json', 'weights': 'cnn_model.weights.h5'}, f)\n","print(\"CNN model structure and weights paths saved in 'cnn_model.pkl'\")"],"metadata":{"trusted":true,"id":"goTkyrVirzAP","executionInfo":{"status":"aborted","timestamp":1748546187888,"user_tz":-420,"elapsed":27256,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":["# Load the .pkl file\n","with open('cnn_model.pkl', 'rb') as f:\n","    data = pickle.load(f)\n","\n","# Load model architecture from JSON\n","with open(data['model_json'], 'r') as json_file:\n","    cnn_model_json = json_file.read()\n","\n","# Reconstruct the model and load weights\n","cnn_model = tf.keras.models.model_from_json(cnn_model_json)\n","cnn_model.load_weights(data['weights'])\n","print(\"CNN model loaded from 'cnn_model.pkl'\")"],"metadata":{"trusted":true,"id":"tAzR-sQNrzAP","executionInfo":{"status":"aborted","timestamp":1748546187891,"user_tz":-420,"elapsed":27255,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null},{"cell_type":"code","source":[],"metadata":{"trusted":true,"id":"F-m9gOTsrzAQ","executionInfo":{"status":"aborted","timestamp":1748546187896,"user_tz":-420,"elapsed":27256,"user":{"displayName":"NGUY·ªÑN ƒê·ª®C TH·∫ÆNG","userId":"15636327107964122138"}}},"outputs":[],"execution_count":null}]}