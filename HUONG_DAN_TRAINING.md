# HÆ¯á»šNG DáºªN TRAINING MODEL FEDERATED LEARNING
## PhÃ¡t Hiá»‡n Táº¥n CÃ´ng Máº¡ng IoT

**TÃ¡c giáº£:** Nguyá»…n Äá»©c Tháº¯ng  
**NgÃ y:** 28/12/2025  
**PhiÃªn báº£n:** 1.0

---

## ğŸ“‹ Má»¤C Lá»¤C

1. [Giá»›i Thiá»‡u](#1-giá»›i-thiá»‡u)
2. [YÃªu Cáº§u Há»‡ Thá»‘ng](#2-yÃªu-cáº§u-há»‡-thá»‘ng)
3. [CÃ i Äáº·t MÃ´i TrÆ°á»ng](#3-cÃ i-Ä‘áº·t-mÃ´i-trÆ°á»ng)
4. [Cáº¥u TrÃºc ThÆ° Má»¥c](#4-cáº¥u-trÃºc-thÆ°-má»¥c)
5. [Cáº¥u HÃ¬nh Training](#5-cáº¥u-hÃ¬nh-training)
6. [HÆ°á»›ng Dáº«n Cháº¡y Tá»«ng BÆ°á»›c](#6-hÆ°á»›ng-dáº«n-cháº¡y-tá»«ng-bÆ°á»›c)
7. [Xá»­ LÃ½ Lá»—i ThÆ°á»ng Gáº·p](#7-xá»­-lÃ½-lá»—i-thÆ°á»ng-gáº·p)
8. [Kiá»ƒm Tra Káº¿t Quáº£](#8-kiá»ƒm-tra-káº¿t-quáº£)
9. [Tips & Best Practices](#9-tips--best-practices)

---

## 1. GIá»šI THIá»†U

### 1.1 Má»¥c ÄÃ­ch
HÆ°á»›ng dáº«n nÃ y giÃºp báº¡n training model Federated Learning Ä‘á»ƒ phÃ¡t hiá»‡n 34 loáº¡i táº¥n cÃ´ng máº¡ng IoT sá»­ dá»¥ng dataset CICIoT2023.

### 1.2 Quy TrÃ¬nh Tá»•ng Quan
```
BÆ°á»›c 1: Data Preprocessing (30-60 phÃºt)
   â†“
BÆ°á»›c 2: Federated Training (4-6 giá»)
   â†“
BÆ°á»›c 3: Model Evaluation (10-20 phÃºt)
   â†“
Káº¿t quáº£: Model + Metrics + Visualizations
```

### 1.3 Káº¿t Quáº£ Mong Äá»£i
- âœ… Model accuracy > 95%
- âœ… F1-Score > 0.85 cho táº¥t cáº£ 34 classes
- âœ… Files xuáº¥t ra cho Web App integration

---

## 2. YÃŠU Cáº¦U Há»† THá»NG

### 2.1 Pháº§n Cá»©ng (Tá»‘i Thiá»ƒu)
- **CPU:** Intel Core i5 hoáº·c tÆ°Æ¡ng Ä‘Æ°Æ¡ng
- **RAM:** 16GB (khuyáº¿n nghá»‹ 32GB)
- **á»” cá»©ng:** 20GB trá»‘ng
- **GPU:** KhÃ´ng báº¯t buá»™c (nhÆ°ng khuyáº¿n nghá»‹ Ä‘á»ƒ training nhanh hÆ¡n)

### 2.2 Pháº§n Cá»©ng (Khuyáº¿n Nghá»‹)
- **CPU:** Intel Core i7/i9 hoáº·c AMD Ryzen 7/9
- **RAM:** 32GB+
- **GPU:** NVIDIA GPU vá»›i CUDA support (GTX 1060 trá»Ÿ lÃªn)
- **á»” cá»©ng:** SSD vá»›i 50GB trá»‘ng

### 2.3 Pháº§n Má»m
- **OS:** macOS, Linux, hoáº·c Windows 10/11
- **Python:** 3.8, 3.9, hoáº·c 3.10
- **Jupyter Notebook:** PhiÃªn báº£n má»›i nháº¥t
- **Git:** Äá»ƒ quáº£n lÃ½ code (optional)

### 2.4 Dataset
- **TÃªn:** CICIoT2023
- **KÃ­ch thÆ°á»›c:** ~12GB (169 CSV files)
- **Vá»‹ trÃ­:** Pháº£i cÃ³ trong thÆ° má»¥c `DataSets/`

---

## 3. CÃ€I Äáº¶T MÃ”I TRÆ¯á»œNG

### 3.1 Kiá»ƒm Tra Python Version

Má»Ÿ Terminal vÃ  cháº¡y:

```bash
python3 --version
```

**Káº¿t quáº£ mong Ä‘á»£i:** Python 3.8.x, 3.9.x, hoáº·c 3.10.x

âš ï¸ **Náº¿u khÃ´ng cÃ³ Python 3:** Download tá»« https://www.python.org/downloads/

---

### 3.2 CÃ i Äáº·t Dependencies

#### BÆ°á»›c 1: Má»Ÿ Terminal
```bash
cd "/Users/user/Documents/Äá»’ ÃN/Do an"
```

#### BÆ°á»›c 2: CÃ i Ä‘áº·t packages
```bash
pip3 install tensorflow keras scikit-learn pandas numpy matplotlib seaborn pyyaml jupyter
```

**Thá»i gian:** 5-10 phÃºt

#### BÆ°á»›c 3: Verify cÃ i Ä‘áº·t
```bash
python3 -c "import tensorflow as tf; import keras; import sklearn; import pandas; import numpy; import matplotlib; import seaborn; import yaml; print('âœ… All packages installed successfully!')"
```

**Káº¿t quáº£ mong Ä‘á»£i:**
```
âœ… All packages installed successfully!
```

---

### 3.3 Kiá»ƒm Tra GPU (Optional nhÆ°ng khuyáº¿n nghá»‹)

```bash
python3 -c "import tensorflow as tf; gpus = tf.config.list_physical_devices('GPU'); print(f'GPU available: {len(gpus) > 0}'); print(f'Number of GPUs: {len(gpus)}')"
```

**Náº¿u cÃ³ GPU:**
```
GPU available: True
Number of GPUs: 1
```

**Náº¿u khÃ´ng cÃ³ GPU:**
```
GPU available: False
Number of GPUs: 0
```

âš ï¸ **LÆ°u Ã½:** KhÃ´ng cÃ³ GPU váº«n cháº¡y Ä‘Æ°á»£c, nhÆ°ng sáº½ cháº­m hÆ¡n 3-4 láº§n.

---

### 3.4 Verify Dataset

```bash
ls -lh DataSets/*.csv | wc -l
```

**Káº¿t quáº£ mong Ä‘á»£i:** `169`

âš ï¸ **Náº¿u khÃ´ng Ä‘á»§ 169 files:** Kiá»ƒm tra láº¡i dataset download.

---

## 4. Cáº¤U TRÃšC THÆ¯ Má»¤C

Sau khi setup xong, cáº¥u trÃºc thÆ° má»¥c cá»§a báº¡n sáº½ nhÆ° sau:

```
Do an/
â”œâ”€â”€ DataSets/                          # Dataset (169 CSV files)
â”‚   â”œâ”€â”€ part-00000-*.csv
â”‚   â”œâ”€â”€ part-00001-*.csv
â”‚   â””â”€â”€ ... (169 files total)
â”‚
â”œâ”€â”€ Notebooks/                         # Code vÃ  notebooks
â”‚   â”œâ”€â”€ 1_Data_Preprocessing.ipynb    # â­ Notebook 1
â”‚   â”œâ”€â”€ 2_Federated_Training.ipynb    # â­ Notebook 2
â”‚   â”œâ”€â”€ 3_Model_Evaluation_Export.ipynb # â­ Notebook 3
â”‚   â”œâ”€â”€ includes.py                    # Constants
â”‚   â”œâ”€â”€ README.md                      # Documentation
â”‚   â”œâ”€â”€ configs/
â”‚   â”‚   â””â”€â”€ training_config.yaml      # âš™ï¸ Configuration
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ data_utils.py             # Data processing
â”‚       â”œâ”€â”€ model_utils.py            # Model architecture
â”‚       â””â”€â”€ fl_utils.py               # FL logic
â”‚
â””â”€â”€ Output/                            # Káº¿t quáº£ training
    â”œâ”€â”€ models/                        # Model files
    â”œâ”€â”€ metrics/                       # Metrics vÃ  plots
    â””â”€â”€ data/                          # Partitioned data
```

---

## 5. Cáº¤U HÃŒNH TRAINING

### 5.1 File Cáº¥u HÃ¬nh

File cáº¥u hÃ¬nh chÃ­nh: `Notebooks/configs/training_config.yaml`

### 5.2 CÃ¡c Tham Sá»‘ Quan Trá»ng

#### **Federated Learning Settings**
```yaml
num_clients: 5          # Sá»‘ lÆ°á»£ng clients (devices) giáº£ láº­p
num_rounds: 30          # Sá»‘ vÃ²ng training (tÄƒng lÃªn 50 náº¿u cáº§n)
local_epochs: 5         # Sá»‘ epochs má»—i client train
batch_size: 256         # Batch size
```

#### **Model Architecture**
```yaml
model:
  input_dim: 46              # Sá»‘ features
  hidden_layers: [128, 64, 32]  # KÃ­ch thÆ°á»›c hidden layers
  num_classes: 34            # Sá»‘ loáº¡i táº¥n cÃ´ng
  dropout_rate: 0.3          # Dropout Ä‘á»ƒ trÃ¡nh overfitting
```

#### **Optimizer**
```yaml
optimizer:
  type: adam
  learning_rate: 0.001      # Learning rate
```

#### **Data Processing**
```yaml
data:
  test_split_ratio: 0.2     # 20% data cho test
  chunk_size: 50000         # Chunk size khi load CSV
  partition_strategy: non_iid  # Non-IID distribution
```

---

### 5.3 Cháº¿ Äá»™ Test (Khuyáº¿n Nghá»‹ Cho Láº§n Äáº§u)

**âš ï¸ QUAN TRá»ŒNG:** Láº§n Ä‘áº§u cháº¡y, nÃªn test vá»›i 10% data trÆ°á»›c!

Má»Ÿ file `Notebooks/configs/training_config.yaml` vÃ  sá»­a:

```yaml
experimental:
  use_sample_data: true     # â† Äá»•i thÃ nh true
  sample_fraction: 0.1      # DÃ¹ng 10% data
```

**Lá»£i Ã­ch:**
- Training chá»‰ máº¥t ~30-60 phÃºt (thay vÃ¬ 5-6 giá»)
- Verify pipeline hoáº¡t Ä‘á»™ng Ä‘Ãºng
- PhÃ¡t hiá»‡n lá»—i sá»›m

**Sau khi test xong, Ä‘á»•i láº¡i:**
```yaml
experimental:
  use_sample_data: false    # â† Äá»•i thÃ nh false Ä‘á»ƒ train full
```

---

## 6. HÆ¯á»šNG DáºªN CHáº Y Tá»ªNG BÆ¯á»šC

### ğŸ“Œ BÆ¯á»šC 1: DATA PREPROCESSING

**Má»¥c Ä‘Ã­ch:** Load, clean, vÃ  partition data cho FL training

#### 1.1 Má»Ÿ Jupyter Notebook

```bash
cd "/Users/user/Documents/Äá»’ ÃN/Do an/Notebooks"
jupyter notebook
```

**Káº¿t quáº£:** Browser sáº½ má»Ÿ vá»›i Jupyter interface.

---

#### 1.2 Má»Ÿ Notebook 1

Trong Jupyter, click vÃ o: `1_Data_Preprocessing.ipynb`

---

#### 1.3 Cháº¡y Tá»«ng Cell

**âš ï¸ QUAN TRá»ŒNG:** Cháº¡y tá»«ng cell theo thá»© tá»± tá»« trÃªn xuá»‘ng dÆ°á»›i!

**CÃ¡ch cháº¡y:**
- Click vÃ o cell
- Nháº¥n `Shift + Enter` (hoáº·c click nÃºt â–¶ï¸ Run)
- Äá»£i cell cháº¡y xong (dáº¥u `*` biáº¿n thÃ nh sá»‘)
- Chuyá»ƒn sang cell tiáº¿p theo

---

#### 1.4 CÃ¡c Cell Quan Trá»ng

**Cell 1-2: Setup and Imports**
```
âœ… All imports successful!
   Number of features: 46
   Label column: label
   Number of attack classes: 34
```

**Cell 3: Load Dataset**
```
ğŸ“‚ Loading dataset from: ../DataSets
   Found 169 CSV files
   [1/169] Loading part-00000-*.csv... âœ“ 123,456 rows
   ...
   Total rows: 12,345,678
```

â±ï¸ **Thá»i gian:** 10-30 phÃºt (tÃ¹y RAM vÃ  CPU)

**Cell 5: Encode Labels**
```
ğŸ·ï¸  Encoding labels...
   Found 34 unique labels:
   âœ“ Encoded 34 classes to numeric values (0-33)
   ğŸ’¾ Saved label encoder to: ../Output/models/label_encoder.pkl
   ğŸ’¾ Saved label mapping to: ../Output/models/labels.json
```

**Cell 6: Normalize Features**
```
ğŸ“ Normalizing features...
   âœ“ Normalized 46 features to [0, 1] range
   ğŸ’¾ Saved scaler to: ../Output/models/scaler.pkl
```

**Cell 7: Partition Data**
```
ğŸ”€ Partitioning data for 5 clients (Non-IID)...
   Train set: 9,876,543 samples
   Test set: 2,469,135 samples
   Client 0 (DDoS): 1,234,567 samples
   Client 1 (Recon): 1,123,456 samples
   ...
```

**Cell 8: Save Data**
```
ğŸ’¾ Saving partitioned data to: ../Output/data
   âœ“ Saved client_0: ../Output/data/client_0_data.npz (123,456 samples)
   ...
   âœ… All data saved successfully!
```

---

#### 1.5 Verify Outputs

**Cell cuá»‘i (Verification):**
```
ğŸ” Verifying saved files...

ğŸ“‚ Data files:
   âœ“ client_0_data.npz (234.56 MB)
   âœ“ client_1_data.npz (223.45 MB)
   âœ“ client_2_data.npz (245.67 MB)
   âœ“ client_3_data.npz (212.34 MB)
   âœ“ client_4_data.npz (256.78 MB)
   âœ“ test_data.npz (567.89 MB)

ğŸ“‚ Model artifacts:
   âœ“ scaler.pkl (12.34 KB)
   âœ“ label_encoder.pkl (5.67 KB)
   âœ“ labels.json (1.23 KB)

âœ… Verification complete!
```

---

#### 1.6 Kiá»ƒm Tra ThÆ° Má»¥c Output

```bash
ls -lh ../Output/data/
ls -lh ../Output/models/
```

**Pháº£i cÃ³:**
- 6 files `.npz` trong `Output/data/`
- 3 files (scaler, encoder, labels) trong `Output/models/`

---

### âœ… CHECKPOINT 1: Data Preprocessing HoÃ n ThÃ nh

Náº¿u táº¥t cáº£ cells cháº¡y thÃ nh cÃ´ng vÃ  cÃ³ Ä‘á»§ files â†’ Chuyá»ƒn sang BÆ°á»›c 2!

---

### ğŸ“Œ BÆ¯á»šC 2: FEDERATED LEARNING TRAINING

**Má»¥c Ä‘Ã­ch:** Train model sá»­ dá»¥ng Federated Learning (FedAvg)

â±ï¸ **Thá»i gian dá»± kiáº¿n:**
- Vá»›i 10% data: 30-60 phÃºt
- Vá»›i 100% data + GPU: 4-6 giá»
- Vá»›i 100% data + CPU: 8-12 giá»

---

#### 2.1 Má»Ÿ Notebook 2

Trong Jupyter, click vÃ o: `2_Federated_Training.ipynb`

---

#### 2.2 Cháº¡y Tá»«ng Cell

**Cell 1: Setup and Imports**
```
âœ… GPU available: 1 device(s)  # Hoáº·c "No GPU found" náº¿u dÃ¹ng CPU
âœ… TensorFlow version: 2.x.x
âœ… Keras version: 2.x.x
```

**Cell 2: Load Configuration**
```
ğŸ“„ Configuration loaded:

ğŸ”§ FL Settings:
   Number of clients: 5
   Number of rounds: 30
   Local epochs: 5
   Batch size: 256

ğŸ—ï¸  Model Architecture:
   Input dim: 46
   Hidden layers: [128, 64, 32]
   Output classes: 34
   Dropout rate: 0.3
```

**Cell 3: Load Preprocessed Data**
```
ğŸ“‚ Loading client data...

   âœ“ client_0: 1,234,567 samples
   âœ“ client_1: 1,123,456 samples
   âœ“ client_2: 1,345,678 samples
   âœ“ client_3: 1,234,567 samples
   âœ“ client_4: 1,456,789 samples
   âœ“ test: 2,469,135 samples

âœ… All data loaded successfully!
```

**Cell 4: Create Global Model**
```
ğŸ—ï¸  Creating DNN model...
   Input dimension: 46
   Hidden layers: [128, 64, 32]
   Output classes: 34
   Dropout rate: 0.3
   âœ“ Model created with 3 hidden layers

âš™ï¸  Compiling model...
   Optimizer: Adam (lr=0.001)
   Loss: sparse_categorical_crossentropy
   Metrics: ['accuracy']
   âœ“ Model compiled successfully

MODEL ARCHITECTURE SUMMARY
================================================================
Layer (type)                 Output Shape              Param #   
================================================================
dense_1 (Dense)              (None, 128)               6016      
dropout_1 (Dropout)          (None, 128)               0         
dense_2 (Dense)              (None, 64)                8256      
dropout_2 (Dropout)          (None, 64)                0         
dense_3 (Dense)              (None, 32)                2080      
dropout_3 (Dropout)          (None, 32)                0         
output (Dense)               (None, 34)                1122      
================================================================
Total parameters: 17,474
Estimated model size: 0.07 MB
```

**Cell 5: Initialize Server and Clients**
```
ğŸ–¥ï¸  Initializing Federated Server...
   âœ“ Server initialized

ğŸ‘¥ Initializing Federated Clients...
   Client 0 initialized with 1,234,567 samples
   Client 1 initialized with 1,123,456 samples
   ...

âœ… 5 clients initialized!
```

---

#### 2.3 Cell 6: Main Training Loop âš ï¸ QUAN TRá»ŒNG

**ÄÃ¢y lÃ  cell máº¥t nhiá»u thá»i gian nháº¥t!**

```
ğŸ• Training started at: 2025-12-28 01:30:00

================================================================================
FEDERATED LEARNING TRAINING
================================================================================
Number of clients: 5
Number of rounds: 30
Local epochs per round: 5
Batch size: 256
Test set size: 2,469,135
================================================================================

================================================================================
ROUND 1/30
================================================================================
ğŸ“¡ Broadcasting global model to 5 clients...
   âœ“ Server initialized

   Client 0 training... âœ“ Loss: 2.3456, Acc: 0.3456
   Client 1 training... âœ“ Loss: 2.4567, Acc: 0.3234
   Client 2 training... âœ“ Loss: 2.3789, Acc: 0.3567
   Client 3 training... âœ“ Loss: 2.4012, Acc: 0.3345
   Client 4 training... âœ“ Loss: 2.3890, Acc: 0.3478

ğŸ”„ Aggregating weights from 5 clients...
   âœ“ Global model updated

ğŸ“Š Evaluating global model on test set...

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROUND 1 SUMMARY:
   Global Test Loss: 2.3945
   Global Test Accuracy: 0.3456 (34.56%)
   Avg Client Loss: 2.3943
   Avg Client Accuracy: 0.3416
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

... (Rounds 2-29 tÆ°Æ¡ng tá»±)

================================================================================
ROUND 30/30
================================================================================
...
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ROUND 30 SUMMARY:
   Global Test Loss: 0.1234
   Global Test Accuracy: 0.9678 (96.78%)  â† Má»¥c tiÃªu >95%!
   Avg Client Loss: 0.1245
   Avg Client Accuracy: 0.9654
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

================================================================================
TRAINING COMPLETED!
================================================================================
Final Test Accuracy: 96.78%
================================================================================

ğŸ• Training completed at: 2025-12-28 07:30:00
â±ï¸  Total training time: 6:00:00
   (360.00 minutes)
```

**â±ï¸ Theo dÃµi tiáº¿n Ä‘á»™:**
- Má»—i round máº¥t ~10-15 phÃºt (vá»›i full data + GPU)
- Accuracy sáº½ tÄƒng dáº§n qua cÃ¡c rounds
- Náº¿u accuracy khÃ´ng tÄƒng sau 10 rounds â†’ CÃ³ váº¥n Ä‘á», xem pháº§n Troubleshooting

---

#### 2.4 CÃ¡c Cell Tiáº¿p Theo

**Cell 7: Visualize Training Progress**

Sáº½ hiá»ƒn thá»‹ 2 biá»ƒu Ä‘á»“:
- Accuracy vs Round (Ä‘Æ°á»ng tÄƒng dáº§n, vÆ°á»£t 95% line)
- Loss vs Round (Ä‘Æ°á»ng giáº£m dáº§n)

**Cell 8: Save Trained Model**
```
ğŸ’¾ Global model saved to: ../Output/models/global_model.h5

âœ… Model saved successfully!
   Path: ../Output/models/global_model.h5
   Size: 12.34 MB
```

**Cell 9: Save Training History**
```
ğŸ’¾ Training history saved to: ../Output/metrics/training_history.json
```

**Cell 10: Quick Evaluation**
```
ğŸ” Loading saved model for verification...
ğŸ“‚ Loading model from: ../Output/models/global_model.h5
   âœ“ Model loaded successfully

ğŸ“Š Evaluating on test set...

âœ… Test Set Results:
   Loss: 0.1234
   Accuracy: 0.9678 (96.78%)

ğŸ”® Sample predictions (first 10 test samples):
   âœ“ Sample 1: Predicted=0, True=0
   âœ“ Sample 2: Predicted=5, True=5
   âœ— Sample 3: Predicted=12, True=11  â† Sai 1 sample
   ...
```

---

### âœ… CHECKPOINT 2: Training HoÃ n ThÃ nh

Náº¿u:
- âœ… Training cháº¡y háº¿t 30 rounds
- âœ… Final accuracy > 95%
- âœ… Model saved thÃ nh cÃ´ng

â†’ Chuyá»ƒn sang BÆ°á»›c 3!

---

### ğŸ“Œ BÆ¯á»šC 3: MODEL EVALUATION & EXPORT

**Má»¥c Ä‘Ã­ch:** ÄÃ¡nh giÃ¡ chi tiáº¿t model vÃ  táº¡o visualizations cho bÃ¡o cÃ¡o

â±ï¸ **Thá»i gian:** 10-20 phÃºt

---

#### 3.1 Má»Ÿ Notebook 3

Trong Jupyter, click vÃ o: `3_Model_Evaluation_Export.ipynb`

---

#### 3.2 Cháº¡y Tá»«ng Cell

**Cell 1-3: Setup, Load Model, Load Labels**
```
âœ… All imports successful!
ğŸ“‚ Loading trained model from: ../Output/models/global_model.h5
   âœ“ Model loaded successfully

âœ… Data loaded:
   Test samples: 2,469,135
   Features: 46
   Classes: 34
```

**Cell 4: Generate Predictions**
```
ğŸ”® Generating predictions on test set...
2469135/2469135 [==============================] - 45s 18us/sample

âœ… Predictions generated!
   Prediction shape: (2469135,)
   Unique predicted classes: 34
```

**Cell 5: Calculate Overall Metrics**
```
================================================================================
OVERALL METRICS
================================================================================

ğŸ“Š Overall Accuracy: 0.9678 (96.78%)  â† Äáº¡t má»¥c tiÃªu!

ğŸ“ˆ Macro Averages (unweighted):
   Precision: 0.9534
   Recall: 0.9512
   F1-Score: 0.9523

ğŸ“ˆ Weighted Averages (by support):
   Precision: 0.9689
   Recall: 0.9678
   F1-Score: 0.9683
================================================================================

âœ… SUCCESS: Target accuracy (>95%) achieved!
```

**Cell 6: Per-Class Metrics**

Hiá»ƒn thá»‹ báº£ng vá»›i 34 rows:
```
                    Class  Precision  Recall  F1-Score  Support
0          BenignTraffic     0.9876  0.9912    0.9894   500000
1      DDoS-RSTFINFlood     0.9654  0.9587    0.9620    75000
2      DDoS-PSHACK_Flood    0.9723  0.9698    0.9710    68000
...
33  DictionaryBruteForce    0.8912  0.8756    0.8833    12000

âœ… All classes have F1-Score >= 0.85!  â† Hoáº·c warning náº¿u cÃ³ class < 0.85
```

**Cell 7-8: Confusion Matrix**

Hiá»ƒn thá»‹ confusion matrix 34x34 (heatmap mÃ u xanh)

```
ğŸ’¾ Confusion matrix saved to: ../Output/metrics/confusion_matrix.png
```

**Cell 9: Training History Visualization**

Hiá»ƒn thá»‹ 2 biá»ƒu Ä‘á»“ training curves

```
ğŸ’¾ Training curves saved to: ../Output/metrics/accuracy_plot.png
```

**Cell 10: Per-Class F1-Score Visualization**

Hiá»ƒn thá»‹ bar chart vá»›i mÃ u xanh (F1â‰¥0.85) vÃ  Ä‘á» (F1<0.85)

```
ğŸ’¾ F1-Score chart saved to: ../Output/metrics/f1_scores_per_class.png

ğŸ“Š F1-Score Summary:
   Classes with F1 â‰¥ 0.85: 34/34 (100.0%)
   Classes with F1 < 0.85: 0/34 (0.0%)
```

**Cell 11: Export Comprehensive Metrics Report**
```
ğŸ’¾ Comprehensive metrics report saved to: ../Output/metrics/metrics_report.json

âœ… Report includes:
   - Overall metrics (accuracy, precision, recall, F1)
   - Per-class metrics for all 34 classes
   - Confusion matrix
   - Summary statistics
```

**Cell 12: Generate Classification Report**
```
================================================================================
CLASSIFICATION REPORT
================================================================================
                       precision    recall  f1-score   support

       BenignTraffic       0.99      0.99      0.99    500000
   DDoS-RSTFINFlood       0.97      0.96      0.96     75000
  DDoS-PSHACK_Flood       0.97      0.97      0.97     68000
...
DictionaryBruteForce       0.89      0.88      0.88     12000

            accuracy                           0.97   2469135
           macro avg       0.95      0.95      0.95   2469135
        weighted avg       0.97      0.97      0.97   2469135

ğŸ’¾ Classification report saved to: ../Output/metrics/classification_report.txt
```

---

### âœ… CHECKPOINT 3: Evaluation HoÃ n ThÃ nh

Kiá»ƒm tra thÆ° má»¥c `Output/`:

```bash
ls -lh ../Output/models/
ls -lh ../Output/metrics/
```

**Pháº£i cÃ³:**

**Models:**
- âœ… `global_model.h5` (~10-20 MB)
- âœ… `scaler.pkl`
- âœ… `label_encoder.pkl`
- âœ… `labels.json`

**Metrics:**
- âœ… `training_history.json`
- âœ… `metrics_report.json`
- âœ… `classification_report.txt`
- âœ… `confusion_matrix.png`
- âœ… `accuracy_plot.png`
- âœ… `f1_scores_per_class.png`

---

## 7. Xá»¬ LÃ Lá»–I THÆ¯á»œNG Gáº¶P

### 7.1 Lá»—i: Out of Memory (OOM)

**Triá»‡u chá»©ng:**
```
MemoryError: Unable to allocate array
```

**NguyÃªn nhÃ¢n:** RAM khÃ´ng Ä‘á»§ Ä‘á»ƒ load dataset

**Giáº£i phÃ¡p:**

**Option 1: Giáº£m chunk_size**
```yaml
# File: configs/training_config.yaml
data:
  chunk_size: 10000  # Giáº£m tá»« 50000 xuá»‘ng 10000
```

**Option 2: DÃ¹ng sample data**
```yaml
experimental:
  use_sample_data: true
  sample_fraction: 0.1  # Chá»‰ dÃ¹ng 10%
```

**Option 3: Close cÃ¡c app khÃ¡c**
- ÄÃ³ng browser tabs khÃ´ng cáº§n thiáº¿t
- ÄÃ³ng cÃ¡c á»©ng dá»¥ng náº·ng (Photoshop, video editors, etc.)

---

### 7.2 Lá»—i: Training KhÃ´ng Converge

**Triá»‡u chá»©ng:**
- Accuracy khÃ´ng tÄƒng sau 10 rounds
- Accuracy dao Ä‘á»™ng khÃ´ng á»•n Ä‘á»‹nh

**Giáº£i phÃ¡p:**

**Option 1: TÄƒng sá»‘ rounds**
```yaml
num_rounds: 50  # TÄƒng tá»« 30 lÃªn 50
```

**Option 2: Giáº£m learning rate**
```yaml
optimizer:
  learning_rate: 0.0005  # Giáº£m tá»« 0.001 xuá»‘ng 0.0005
```

**Option 3: TÄƒng local epochs**
```yaml
local_epochs: 7  # TÄƒng tá»« 5 lÃªn 7
```

---

### 7.3 Lá»—i: File Not Found

**Triá»‡u chá»©ng:**
```
FileNotFoundError: No such file or directory: '../DataSets'
```

**Giáº£i phÃ¡p:**
1. Kiá»ƒm tra dataset cÃ³ trong thÆ° má»¥c Ä‘Ãºng khÃ´ng:
   ```bash
   ls -lh ../DataSets/*.csv | wc -l
   ```
2. Náº¿u khÃ´ng cÃ³, download láº¡i dataset
3. Äáº£m báº£o Ä‘Æ°á»ng dáº«n Ä‘Ãºng trong notebook

---

### 7.4 Lá»—i: Import Error

**Triá»‡u chá»©ng:**
```
ModuleNotFoundError: No module named 'tensorflow'
```

**Giáº£i phÃ¡p:**
```bash
pip3 install tensorflow keras scikit-learn pandas numpy matplotlib seaborn pyyaml
```

---

### 7.5 Lá»—i: GPU Not Found (KhÃ´ng pháº£i lá»—i nghiÃªm trá»ng)

**Triá»‡u chá»©ng:**
```
âš ï¸  No GPU found. Training will use CPU (slower).
```

**Giáº£i phÃ¡p:**
- KhÃ´ng cáº§n lÃ m gÃ¬, váº«n train Ä‘Æ°á»£c
- Chá»‰ cháº­m hÆ¡n 3-4 láº§n
- Náº¿u muá»‘n dÃ¹ng GPU: CÃ i CUDA vÃ  cuDNN (phá»©c táº¡p)

---

### 7.6 Lá»—i: Jupyter Kernel Died

**Triá»‡u chá»©ng:**
```
The kernel appears to have died. It will restart automatically.
```

**NguyÃªn nhÃ¢n:** RAM khÃ´ng Ä‘á»§ hoáº·c code cÃ³ bug

**Giáº£i phÃ¡p:**
1. Restart kernel: `Kernel` â†’ `Restart`
2. Giáº£m sample_fraction xuá»‘ng 0.05 (5%)
3. Cháº¡y láº¡i tá»« Ä‘áº§u

---

## 8. KIá»‚M TRA Káº¾T QUáº¢

### 8.1 Checklist HoÃ n ThÃ nh

- [ ] **Data Preprocessing:**
  - [ ] 6 files `.npz` trong `Output/data/`
  - [ ] 3 files artifacts trong `Output/models/`

- [ ] **Training:**
  - [ ] `global_model.h5` trong `Output/models/`
  - [ ] `training_history.json` trong `Output/metrics/`
  - [ ] Final accuracy > 95%

- [ ] **Evaluation:**
  - [ ] 3 PNG files (confusion matrix, accuracy plot, F1 chart)
  - [ ] `metrics_report.json`
  - [ ] `classification_report.txt`

---

### 8.2 Kiá»ƒm Tra Model Quality

**Accuracy:**
```
âœ… Overall accuracy > 95%
```

**F1-Score:**
```
âœ… All 34 classes have F1-Score > 0.85
```

**Confusion Matrix:**
```
âœ… Diagonal cÃ³ giÃ¡ trá»‹ cao (correct predictions)
âœ… Off-diagonal cÃ³ giÃ¡ trá»‹ tháº¥p (misclassifications)
```

---

### 8.3 Xem Káº¿t Quáº£

**Má»Ÿ visualizations:**
```bash
open ../Output/metrics/confusion_matrix.png
open ../Output/metrics/accuracy_plot.png
open ../Output/metrics/f1_scores_per_class.png
```

**Äá»c metrics:**
```bash
cat ../Output/metrics/classification_report.txt
```

---

## 9. TIPS & BEST PRACTICES

### 9.1 Láº§n Äáº§u Cháº¡y

âœ… **LuÃ´n test vá»›i 10% data trÆ°á»›c:**
```yaml
experimental:
  use_sample_data: true
  sample_fraction: 0.1
```

âœ… **Cháº¡y vÃ o ban Ä‘Ãªm hoáº·c cuá»‘i tuáº§n:**
- Training full data máº¥t 5-7 giá»
- Äá»ƒ mÃ¡y cháº¡y qua Ä‘Ãªm

âœ… **KhÃ´ng táº¯t mÃ¡y khi Ä‘ang training:**
- Sáº½ máº¥t háº¿t tiáº¿n Ä‘á»™
- Pháº£i cháº¡y láº¡i tá»« Ä‘áº§u

---

### 9.2 Monitoring

âœ… **Theo dÃµi accuracy sau má»—i 5 rounds:**
- Náº¿u tÄƒng Ä‘á»u â†’ OK
- Náº¿u khÃ´ng tÄƒng â†’ CÃ³ váº¥n Ä‘á»

âœ… **Check RAM usage:**
```bash
# macOS
top -l 1 | grep PhysMem

# Linux
free -h
```

âœ… **Check disk space:**
```bash
df -h
```

---

### 9.3 Backup

âœ… **Backup model sau khi train xong:**
```bash
cp -r Output/ Output_backup_$(date +%Y%m%d)/
```

âœ… **Backup training history:**
```bash
cp Output/metrics/training_history.json training_history_$(date +%Y%m%d).json
```

---

### 9.4 Optimization

**Náº¿u muá»‘n train nhanh hÆ¡n:**

1. **Giáº£m num_rounds:**
   ```yaml
   num_rounds: 20  # Thay vÃ¬ 30
   ```

2. **Giáº£m local_epochs:**
   ```yaml
   local_epochs: 3  # Thay vÃ¬ 5
   ```

3. **TÄƒng batch_size (náº¿u RAM Ä‘á»§):**
   ```yaml
   batch_size: 512  # Thay vÃ¬ 256
   ```

**âš ï¸ LÆ°u Ã½:** CÃ³ thá»ƒ giáº£m accuracy!

---

### 9.5 Troubleshooting Nhanh

| Váº¥n Ä‘á» | Giáº£i phÃ¡p |
|--------|-----------|
| OOM | Giáº£m chunk_size hoáº·c dÃ¹ng sample |
| Training cháº­m | DÃ¹ng GPU hoáº·c giáº£m data |
| Accuracy tháº¥p | TÄƒng rounds hoáº·c giáº£m learning_rate |
| Kernel died | Restart vÃ  giáº£m sample_fraction |

---

## 10. Káº¾T LUáº¬N

### 10.1 Tá»•ng Káº¿t

Sau khi hoÃ n thÃ nh 3 notebooks, báº¡n sáº½ cÃ³:

âœ… **Model trained** vá»›i accuracy > 95%  
âœ… **Metrics chi tiáº¿t** cho táº¥t cáº£ 34 classes  
âœ… **Visualizations Ä‘áº¹p** cho bÃ¡o cÃ¡o Ä‘á»“ Ã¡n  
âœ… **Artifacts Ä‘áº§y Ä‘á»§** cho Web App integration  

---

### 10.2 Thá»i Gian Dá»± Kiáº¿n

| Giai Ä‘oáº¡n | 10% Data | 100% Data (GPU) | 100% Data (CPU) |
|-----------|----------|-----------------|-----------------|
| Data Preprocessing | 5-10 mins | 30-60 mins | 30-60 mins |
| FL Training | 30-60 mins | 4-6 hours | 8-12 hours |
| Evaluation | 5 mins | 10-20 mins | 10-20 mins |
| **TOTAL** | **40-75 mins** | **5-7 hours** | **9-13 hours** |

---

### 10.3 Next Steps

1. âœ… Review táº¥t cáº£ visualizations
2. âœ… ÄÆ°a plots vÃ o bÃ¡o cÃ¡o Ä‘á»“ Ã¡n
3. âœ… Chuáº©n bá»‹ demo cho giáº£ng viÃªn
4. âœ… Báº¯t Ä‘áº§u xÃ¢y dá»±ng Web App (sá»­ dá»¥ng model Ä‘Ã£ train)

---

## ğŸ“ Há»– TRá»¢

Náº¿u gáº·p váº¥n Ä‘á»:

1. **Äá»c láº¡i pháº§n Troubleshooting** (Section 7)
2. **Check logs** trong notebook cells
3. **Google error message** cá»¥ thá»ƒ
4. **Há»i giáº£ng viÃªn** hoáº·c báº¡n bÃ¨

---

**ChÃºc báº¡n training thÃ nh cÃ´ng! ğŸš€**

---

**NgÃ y cáº­p nháº­t:** 28/12/2025  
**PhiÃªn báº£n:** 1.0  
**TÃ¡c giáº£:** Nguyá»…n Äá»©c Tháº¯ng
