# Federated Learning Training Configuration
# Project: IoT Network Attack Detection using Federated Learning
# Dataset: CICIoT2023

# ============================================================================
# FRAMEWORK SELECTION
# ============================================================================
framework: pytorch            # Framework: 'tensorflow' (DNN) or 'pytorch' (TabTransformer)

# ============================================================================
# FEDERATED LEARNING SETTINGS
# ============================================================================
num_clients: 5                # Number of simulated IoT devices/clients
num_rounds: 30                # FL communication rounds (increased from 10 to 30 for better convergence)
local_epochs: 10               # Training epochs per client per round (reduced from 20 to 5 for FL stability)
batch_size: 256               # Batch size for local training
random_seed: 42               # For reproducibility

# ============================================================================
# MODEL ARCHITECTURE (TensorFlow DNN - used when framework='tensorflow')
# ============================================================================
model:
  input_dim: 46               # Number of features (from includes.py::X_columns)
  hidden_layers: [128, 64, 32]  # Hidden layer sizes (progressive reduction)
  num_classes: 34             # Number of attack types (from includes.py::dict_34_classes)
  dropout_rate: 0.3           # Dropout for regularization
  activation: relu            # Activation function for hidden layers
  output_activation: softmax  # Output layer activation

# ============================================================================
# TABTRANSFORMER ARCHITECTURE (PyTorch - used when framework='pytorch')
# ============================================================================
tabtransformer:
  embedding_dim: 32           # Dimension for embeddings (categorical and numerical)
  num_transformer_layers: 2   # Number of transformer encoder layers
  num_attention_heads: 4      # Number of attention heads per layer
  ff_hidden_dim: 128          # Feed-forward network hidden dimension
  dropout_rate: 0.1           # Dropout rate for regularization
  attention_dropout: 0.1      # Dropout rate for attention weights
  use_cls_token: true         # Use CLS token for classification (vs mean pooling)

# ============================================================================
# FEATURE CONFIGURATION
# ============================================================================
features:
  # Categorical vs Numerical split
  # If empty, will auto-detect or use default (20 categorical, 26 numerical)
  categorical_indices: []     # List of categorical feature indices (0-based)
  numerical_indices: []       # List of numerical feature indices (0-based)
  
  # Categorical feature cardinalities (unique values per feature)
  # Required for TabTransformer - will be auto-detected if empty
  categorical_cardinalities: []  # e.g. [10, 5, 100, 50, ...]
  
  # Note: For CICIoT2023 dataset, typical split is ~20 categorical, ~26 numerical
  # Categorical: protocol, source/dest ports, flags, connection state, etc.
  # Numerical: packet counts, byte counts, durations, rates, etc.

# ============================================================================
# OPTIMIZATION
# ============================================================================
optimizer:
  type: adam                  # Optimizer type
  learning_rate: 0.001        # Learning rate
  beta_1: 0.9                 # Adam beta_1
  beta_2: 0.999               # Adam beta_2
  epsilon: 1.0e-7             # Adam epsilon

loss_function: sparse_categorical_crossentropy  # Loss function
metrics: [accuracy]           # Metrics to track

# ============================================================================
# DATA PROCESSING
# ============================================================================
data:
  test_split_ratio: 0.2       # 80% train, 20% test
  chunk_size: 50000           # Chunk size for loading large CSV files
  normalization: minmax       # Normalization method (minmax or standard)
  partition_strategy: non_iid # Data partitioning strategy (iid or non_iid)
  
  # Non-IID distribution strategy
  # Each client gets majority of specific attack types
  non_iid_config:
    client_0: [DDoS]          # Client 0: 70% DDoS attacks
    client_1: [Recon]         # Client 1: 70% Reconnaissance attacks
    client_2: [Web]           # Client 2: 70% Web attacks
    client_3: [Mirai]         # Client 3: 70% Mirai attacks
    client_4: [Mixed]         # Client 4: Mixed distribution

# ============================================================================
# OUTPUT PATHS
# ============================================================================
paths:
  output_dir: ../Output
  models_dir: models
  metrics_dir: metrics
  data_dir: data
  
  # Output files
  global_model: global_model.h5
  scaler: scaler.pkl
  label_encoder: label_encoder.pkl
  labels_json: labels.json
  training_history: training_history.json
  metrics_report: metrics_report.json

# ============================================================================
# TRAINING CONTROL
# ============================================================================
training:
  early_stopping: false       # Enable early stopping (set to true if needed)
  early_stopping_patience: 10 # Patience for early stopping
  save_checkpoints: true      # Save model checkpoints every N rounds
  checkpoint_frequency: 10    # Save checkpoint every N rounds
  verbose: 1                  # Verbosity level (0=silent, 1=progress, 2=detailed)

# ============================================================================
# EVALUATION
# ============================================================================
evaluation:
  confusion_matrix: true      # Generate confusion matrix
  per_class_metrics: true     # Calculate per-class precision/recall/F1
  visualizations: true        # Generate plots
  
  # Visualization settings
  figure_size: [12, 10]       # Default figure size
  dpi: 300                    # DPI for saved figures
  color_map: Blues            # Color map for confusion matrix

# ============================================================================
# GSA FEATURE SELECTION
# ============================================================================
gsa:
  enabled: true
  num_features_to_select: 20
  
  # --- TỐI ƯU SỐ LƯỢNG TÍNH TOÁN ---
  max_iterations: 30           # Giảm từ 50 xuống 30 (GSA hội tụ khá nhanh)
  population_size: 15          # Giảm từ 30 xuống 15 (Đủ cho không gian 46 features)
  
  # --- CẤU HÌNH VẬT LÝ (GIỮ NGUYÊN) ---
  gravitational_constant: 100.0
  alpha: 20.0
  
  # --- TỐI ƯU DỮ LIỆU ĐẦU VÀO (QUAN TRỌNG NHẤT) ---
  use_sample: true
  sample_fraction: 0.05        # Giảm từ 0.2 (20%) xuống 0.05 (5%)
  random_seed: 42

  # Output paths
  output_dir: ../Output/gsa_results
  selected_features_json: selected_features.json
  convergence_plot: gsa_convergence.png
  feature_importance_json: feature_importance.json

# ============================================================================
# AGGREGATION STRATEGY
# ============================================================================
aggregation:
  method: fedmade               # 'fedavg' or 'fedmade'
  
  # FedMade-specific parameters
  fedmade:
    use_client_metrics: true    # Use validation metrics for scoring
    layer_matching: true        # Enable layer-wise aggregation
    contribution_threshold: 0.2 # Min score to include client (0.0 = no filtering)
    accuracy_weight: 0.7        # Weight for accuracy in contribution score
    loss_weight: 0.3            # Weight for loss in contribution score
    normalize_scores: true      # Normalize scores to sum to 1
    verbose: true               # Log contribution scores each round
    
    # Output paths
    output_dir: ../Output/aggregation_metrics
    contribution_scores_json: contribution_scores.json
    client_metrics_json: client_metrics.json

# ============================================================================
# EXPERIMENTAL SETTINGS (for testing)
# ============================================================================
experimental:
  use_sample_data: false      # Set to true to use only 10% of data for testing
  sample_fraction: 0.1        # Fraction of data to use if use_sample_data=true
  debug_mode: false           # Enable debug logging
